##
#1. I agree that DB is not readable. Alex, please make it in xlsx and add the description of the condition (as in Table 1)

# Кроме того, база должна быть понятной – с разбивкой по датчикам, сгруппированным по интенсивности 
# антропогенной нагрузки с кратким описанием, где установлен и пр., с понятными названиями параметров и в 
# формате xlsx (п. 8.3 ТЗ).
# 
 
#2. Alex, please edit the graphs regarding language (Russian) and readability.
# I can add to the comment from the reviewer that they should be much brighter - so far some lines (like SD of 
# oscillation) are almost invisible. 
# 
# Let's add more graphs comparing the dynamics between different ages and anthropogenic pressures. 
# For the pressures, we assume that Sherbinka is high, Troitsk is low; Bolotnaya is high;
#  Timiryazev is low. Botanical garden and school can be interpreted differently.
#   For Timiryazev we can compare different ages and different distances from the road - it was assumed when we 
#   were planning the research site.
#
# Графики. Добавить ед. измерения параметров. Указать месяц и декады, а не количество дней, а в графиках, где только месяцы, указать название месяца, 
# а не цифру. Это замечание ко всем графикам.
#3.	Также не могу найти графики, отражающие динамику отдельных параметров а) в разных возрастных группах и б) 
#с учетом антропогенной нагрузки.
#
##4. We can mention that we didn't do the dendrochronological analysis, but approximate ages based on the diameter and species are needed.
#
# Было бы хорошо добавить в данные по деревьям (п. 1.3 отчета) их возраст
##
#5. Olga, please add Russian names for all the species all over the report (but tables for VTA) in brackets after Latin name.
#
#5.	Просьба в отчете использовать не латинские, а русские названия пород деревьев. Информация должна быть понятной 
#не только профильным специалистам, латинские наименования будут затруднять восприятие информации
#
#6. Alex, please describe the SD of oscillations in details and explain, why it is better than the other parameters you tried.
#
#	Вопрос по показателю вертикальной устойчивости. «В качестве индикатора колебаний была предложена безразмерная 
#	величина – сумма стандартных отклонений сигнала по осям». Просьба более подробно описать этот индикатор, как он 
#	рассчитывается, и как его интерпретировать.
#	
#	
#7. It kind of duplicates the final table but without literature data.  However, let's do that if required. 
# Giovanna, please take care of it.
#
#В Главе 2 было бы хорошо добавить сводные таблицы параметров для разных видов лиственных и хвойных пород 
#(без разбивки по площадкам), по аналогии с Главой 3
#
#8. Alex, Riccardo, please explain.
#
#С. 30. Почему у ели такие сильные «скачки» NDVI? Порядка 0,25. Разница в 0,1-0,15 ед. – это уже переход из 
#одного класса качественного состояния в другой, либо отражение сезонной динамики, чего у хвойных быть не должно. 
#
#

#9. There was a description of PRI - I can add it. However, the question of why we write about PRI in Chapter 4 
#and about NDVI elsewhere is relevant. Please respond or more likely repeat the PRI for the other chapters and NDVI 
#for Chapter 4. Giovana, Alex, this is the task for you, I guess.
#
#9.	В отчете отсутствует анализ индекса PRI. Но он появляется в конце раздела 4.1 
# как один из критериев верификации. Почему такая логика изложения? 
#
#10. This is an expected question. The easy option - to compare sites as described in p.3. More difficult - 
#to evaluate the distance from the road or from the other sources of anthropogenic pressure per site. 
#The best option is to write a separate chapter comparing anthropogenic pressure similarly like we did with age 
#in Chapter 3 and species in Chapter 2. If you provide graphs and short descriptions I can take care of it.
#
#10.	В отчете отсутствует раздел по сравнительному анализу пространственного разнообразия суточной и сезонной 
#динамики параметров состояния на площадках с разной антропогенной нагрузкой
#
#
#11. Olga, please respond. If your criteria are different from GR-743 we'll have to recalculate the VTA results 
#based on it. The municipality has developed this regulation and they will insist on using it.
#
#11.	Глава 4, раздел 4.1. Нужно указать, откуда взяты градации параметров, по которым оценивалось визуальное 
#состояние. В 822-ПП есть градации по усыхающим ветвям, но они отличаются, от приведенных в отчете. Также 
#целесообразно было бы оценить категорию состояния деревьев по шкале, утвержденной 743-ПП. Если проводится 
#оценка по европейским критериям, необходимо эту классификацию включить в отчет в виде приложения, описать 
#как рассчитывается класс. И сопоставить с нашими критериями из 822-ПП.
#
#12. I propose to implement the T-criteria for all the trees and check whether the categories A and С are 
#significantly different. We can also use one-way ANOVA to do the same with Russian grade (Olga, once again, 
#please, use the  classification from GR-744)
#
#12.	Раздел 4.1. Верификация по 12 деревьям – это очень мало, не репрезентативно. Можно ли дополнить?
# По индексу PRI вопрос выше, почему он выбран для верификации, а не NDVI? Как этот индекс интерпретируется, 
# есть ли классификация?
#

#
#
#13. Alex (Giovanna) please comment.
#
#
#13.	Раздел 4.2. Очень странные получились значения NDVI, и по датчикам, и по спутникам. По имеющимся у 
#нас классификациям, составленным, специализированными организациями, значения NDVI < 0,55 – это сильное усыхание. 
#У Вас много таких низких значений индекса. Кроме того, если сопоставить эти результаты с натурными обследованиями, 
#то очень низкие значения NDVI выскакивают у деревьев в хорошем состоянии, например устройства 259, 263, 279, хотя 
#с такими значениями NDVI – это должны быть сухостойные деревья. Прошу дать комментарий. При этом, в таблице 41 
#приведены совершенно адекватные значения индекса.
#
#
#
#14. We shall add not only optimal, but also extreme values for sapflow and vegetation indexes (NDVI and PRI?) 
#considering age. Basically, for each species we shall add the value for young and old. I can understand that we'll
# likely lack literature data on these details, but we'll have to make a good guess in this case. Riccardo, Giovanna,
#  please take care of this issue. I guess, it is the most important point. 
#  
#14.	В конце отчета приведены только оптимальные значения 2х параметров, тогда так требованиями ТЗ предусмотрена 
#подготовка предложений по оптимальным и экстремальным значениям, в том числе с учетом возраста. Прошу доработать  
#  
#  
#  Таблицы среднихз макс мин значений потока, ндви, для каждого вида усредненный
#  
#  !!!!Посчитать возраста по феногруппам!!!!!! Добавить колонку в первую главу
#  
#  NDVI глава 2 добавить таблицу
#  
#  Расписать кто высокий кто низкий
#  
#  Ответить на TT 259, 263, 279
#  
#  Имена участков
#  
#  Показать что NDVI работает для ВТА и валить на то, что 
#  
#  Внутри сайтовое сравнение антроп нагрузке
#  
#  DONE Ольгу пнуть по ее пунктам
#  
#  Добавить в финальные таблицы наши экстремальные значения 
#  










source("CalcFin\\TTcalc_site_3.R")
library(ggpmisc)
library(extrafont)
library(Rmisc)

loadfonts(device = "win", quiet = TRUE)


installation_start = 1556845000


OLDTIM = TTcalc_site(c("http://naturetalkers.altervista.org/C1880020/ttcloud.txt"),
                     1535637102,
                     import_folder_name=NULL,
                     first_imported_dates_reconstructed = F,
                     "timold_desc.csv")
export_site_to_excel(OLDTIM,sitename="TIMACAD_old",
                     insert_file="TIMOLD_descr.xlsx")


RUDNdata=TTcalc_site(c("http://naturetalkers.altervista.org/C18A0031/ttcloud.txt",
                       "http://naturetalkers.altervista.org/C18A0025/ttcloud.txt"),
                     installation_start,
                     import_folder_name="RUDN",
                     first_imported_dates_reconstructed = F,
                     "all_TT_desc.csv",
                     "RUDN")

TIMdata[[2]] %>% group_by(id)%>% summarise(problems = which(is.na(time))%>%length) %>% as.data.frame
RUDNdata[[2]] %>% group_by(id) %>% summarise(mmoist = mean(moist, na.rm=T))


export_site_to_excel(RUDNdata,sitename="RUDN_all",
                     insert_file="RUDN_descr.xlsx")
#export_site_to_csv_folder(RUDNdata)

TIMdata=TTcalc_site(c("http://naturetalkers.altervista.org/C18A0029/ttcloud.txt",
                      "http://naturetalkers.altervista.org/C18A0030/ttcloud.txt"),
                    installation_start,
                    import_folder_name="TIMR",
                    first_imported_dates_reconstructed = T,
                    "all_TT_desc.csv",
                    "Timiryazev")

export_site_to_excel(TIMdata,sitename="TIMR_all",
                     insert_file="Timir_descr.xlsx")
#export_site_to_csv_folder(TIMdata)

BLTNdata=TTcalc_site("http://naturetalkers.altervista.org/C18A0024/ttcloud.txt",
                     installation_start,
                     import_folder_name=NULL,
                     first_imported_dates_reconstructed = F,
                     "all_TT_desc.csv",
                     "Bolotnaya")

export_site_to_excel(BLTNdata,sitename="Bolotnaya_all",
                     insert_file="Bolotnaya_all.xlsx")
#export_site_to_csv_folder(BLTNdata)


SCHLdata=TTcalc_site("http://naturetalkers.altervista.org/C18A0023/ttcloud.txt",
                     installation_start,
                     import_folder_name=NULL,
                     first_imported_dates_reconstructed = F,
                     "all_TT_desc.csv",
                     "School")
SCHLdata[[2]] %>% group_by(id) %>% filter(moist>0)%>% 
  summarise(mmoist = mean(moist, na.rm=T), msd = sd(moist, na.rm=T))

export_site_to_excel(SCHLdata,sitename="School1234_all",
                     insert_file="School1234_all.xlsx")

#export_site_to_csv_folder(SCHLdata)

SHERdata=TTcalc_site("http://naturetalkers.altervista.org/C1870015/ttcloud.txt",
                     installation_start,
                     import_folder_name=NULL,
                     first_imported_dates_reconstructed = F,
                     "all_TT_desc.csv",
                     "Scherbinka")

export_site_to_excel(SHERdata,sitename="Scherbinka_all",
                     insert_file="Scherbinka_all.xlsx")
#export_site_to_csv_folder(SHERdata)

HORTdata  = TTcalc_site("http://naturetalkers.altervista.org/C18A0026/ttcloud.txt",
                        installation_start,
                        import_folder_name=NULL,
                        first_imported_dates_reconstructed = F,
                        "all_TT_desc.csv",
                        "Botanical")

export_site_to_excel(HORTdata,sitename="Botanical_all",
                     insert_file="Botanical_descr.xlsx")
#export_site_to_csv_folder(HORTdata)

TRSKdata = TTcalc_site("http://naturetalkers.altervista.org/C18A0027/ttcloud.txt",
                       installation_start,
                       import_folder_name = NULL,
                       first_imported_dates_reconstructed = F,
                       "all_TT_desc.csv",
                       "Troick")

export_site_to_excel(TRSKdata,sitename="Troitsk_all",
                     insert_file="Troitsk_descr.xlsx")
#export_site_to_csv_folder(TRSKdata)


RUDNdata[[2]]$Site = "RUDN"
TIMdata[[2]]$Site = "TIMIRYAZEV"
BLTNdata[[2]]$Site = "BOLOTNAYA"
HORTdata[[2]]$Site = "GARDEN"
TRSKdata[[2]]$Site = "TROITSK"
SCHLdata[[2]]$Site = "SCHOOL1234"
SHERdata[[2]]$Site = "SCHERBINKA"


RUDNdata[[2]]$SiteIndex = "OL-1"
TIMdata[[2]]$SiteIndex  = "OL-2"
BLTNdata[[2]]$SiteIndex = "MS-6"
HORTdata[[2]]$SiteIndex = "OL-3"
TRSKdata[[2]]$SiteIndex = "MS-4"
SCHLdata[[2]]$SiteIndex = "MS-7"
SHERdata[[2]]$SiteIndex = "MS-5"





RUDNdata[[1]]$Site = "RUDN"
TIMdata[[1]]$Site = "TIMIRYAZEV"
BLTNdata[[1]]$Site = "BOLOTNAYA"
HORTdata[[1]]$Site = "GARDEN"
TRSKdata[[1]]$Site = "TROITSK"
SCHLdata[[1]]$Site = "SCHOOL1234"
SHERdata[[1]]$Site = "SCHERBINKA"



AllData = rbind(
  RUDNdata[[2]],
  TIMdata[[2]],
  BLTNdata[[2]],
  HORTdata[[2]],
  TRSKdata[[2]],
  SCHLdata[[2]],
  SHERdata[[2]]
)

AllData$month = month(AllData$time)


AllDataRaw = rbind(
  RUDNdata[[1]],
  TIMdata[[1]],
  BLTNdata[[1]],
  HORTdata[[1]],
  TRSKdata[[1]],
  SCHLdata[[1]],
  SHERdata[[1]]
)
write.csv(AllData,"all_data.csv")
write.csv(AllDataRaw,"all_data_raw.csv")




########################### METEO FROM MSU #####################################



read_meteo = function(folder){
  #folder="MSU"
  meteo_files = dir(folder,recursive=T)
  all_meteo_data = data.frame()
  for (file in meteo_files){
    meteo_data <- read_table2(paste(folder,file,sep="/"), 
                              col_types = cols(    `Cр.напр.1` = col_skip(), 
                                                   `Cр.ск.1` = col_skip(), 
                                                   `Tпов.макс_3ч` = col_skip(), 
                                                   `Tпов.мин_3ч` = col_skip(), 
                                                   X46 = col_skip(), 
                                                   `Давление` = col_skip(), 
                                                   `Давление_ур.моря` = col_skip(), 
                                                   `Знач.бар.тенденции` = col_skip(), 
                                                   `МЭД` = col_skip(),
                                                   `Макс.скорость_3ч1` = col_double(), 
                                                   `Мгн.направление1` = col_skip(), 
                                                   `Мгн.скорость1` = col_skip(), 
                                                   `Осадки_12ч` = col_skip(), 
                                                   `Осадки_24ч` = col_skip(), 
                                                   `Осадки_Макс.инт.10мин` = col_skip(), 
                                                   `Осадки_Макс.инт.1ч` = col_skip(), 
                                                   `Осадки_Мин.инт.1ч` = col_skip(), 
                                                   `Отн.влажность` = col_double(), 
                                                   `Порыв1` = col_skip(), 
                                                   `Твозд.` = col_double(), 
                                                   `Твозд.макс_12ч` = col_skip(), 
                                                   `Твозд.макс_3ч` = col_skip(), 
                                                   `Твозд.мин_12ч` = col_skip(), 
                                                   `Твозд.мин_3ч` = col_skip(), 
                                                   `Твозд.ср_сутки` = col_skip(), 
                                                   `Точка_росы` = col_skip(), 
                                                   `Упруг.вод.пара(e)` = col_skip(), 
                                                   `Хар.бар.тенденции` = col_skip(), 
                                                   `время` = col_time(format = "%H:%M:%S"), 
                                                   `дата` = col_date(format = "%d.%m.%Y"), 
                                                   `местн.DT` = col_skip()), 
                              locale = locale(encoding = "WINDOWS-1251"))
    all_meteo_data = rbind(all_meteo_data, meteo_data)
  }
  
  all_meteo_data = all_meteo_data[,1:5]
  names(all_meteo_data) = c("date","time","ta","Rh","WS")
  all_meteo_data  = all_meteo_data %>% 
    mutate(hour=hour(time), doy=yday(date), year = year(date))
  #data = left_join(data,all_meteo_data, by=c("year","doy","hour"))
  return(all_meteo_data)
  
}  


meteo_data  = read_meteo("MSU") %>% group_by(year,doy,hour)%>%
  summarise(Rh = mean(Rh, na.rm = T),ta = mean(ta, na.rm = T), WS=mean(WS, na.rm = T))
#meteo_data$doy %>% max
#data = RUDNdata[[2]]
AllData = left_join(AllData,meteo_data, by=c("year","doy","hour"))
#data$doy
#data$Rh%>%is.na()%>%which()%>%length()

#Climat comparison graphs

data = RUDNdata[[2]]
data = left_join(data,meteo_data, by=c("year","doy","hour"))

tair_pic = ggplot(data=data)+
  geom_point(aes(x=as.Date(time),y=ta),color=2, size=.1, alpha=1/20)+
  geom_point(aes(x=as.Date(time),y=tair),color=3, size=.1, alpha=1/20)+
  geom_smooth(aes(x=as.Date(time),y=ta), model="loess", color=2,span=.01)+
  geom_smooth(aes(x=as.Date(time),y=tair), model="loess", color=3,span=.1)+
  scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                limits = c(as.Date("01.05.2019", "%d.%m.%Y"),NA), name = NULL)+
  scale_y_continuous( limits = c(0,33), name = expression(Температура~" "~воздуха~" "~С^o))+
  theme_bw()
ggsave("Comparison_of_tair_in_RUDNVvsMSU.png", tair_pic,device = "png",width=5.83,height=4.13,units="in")

rh_pic = ggplot(data = data)+
  geom_point(aes(x=as.Date(time),y=Rh),color=2, size=.1, alpha=1/20)+
  geom_point(aes(x=as.Date(time),y=rh),color=3, size=.1, alpha=1/20)+
  geom_smooth(aes(x=as.Date(time),y=Rh), model="loess", color=2,span=.01)+
  geom_smooth(aes(x=as.Date(time),y=rh), model="loess", color=3,span=.1)+
  scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
               limits = c(as.Date("01.05.2019", "%d.%m.%Y"),NA), name = NULL)+
  scale_y_continuous( limits = c(0,100), name = expression(Влажность~" "~воздуха~" "~"%"))+
  theme_bw()

ggsave("Comparison_of_rh_in_RUDNVvsMSU.png", rh_pic,device = "png",width=5.83,height=4.13,units="in")


#####################   AGE d#################################################

# ggplot(data = AllData %>% group_by(id, Species,Site)%>%summarise(DBH = mean(DBH)))+geom_histogram(aes(x= DBH))
# 
# AllData = AllData%>%mutate(AgeGroup = case_when(
#                                       DBH < 60 ~"Первая",
#                                       DBH > 60 & DBH < 90 ~"Вторая",
#                                       DBH > 90 & DBH < 120 ~"Третья",
#                                       DBH > 120 & DBH < 150 ~"Четвертая",
#                                       DBH > 150 & DBH < 180 ~"Пятая",
#                                       DBH > 180  ~"Шестая"),
#                            AgeGroup  = factor(AgeGroup, levels = c("Первая","Вторая","Третья","Четвертая","Пятая","Шестая")))

# AllData = AllData%>%mutate(load = case_when(
#                                       Site == "BOLOTNAYA"  | Site =="SCHOOL1234" ~ "Оч. высокий",
#                                       Site == "RUDN"  | Site == "SCHERBINKA" ~ "Высокий",
#                                       Site == "TROITSK"  | Site =="GARDEN" ~ "Средний",
#                                       Site == "TIMIRYAZEV" ~ "Слабый"),
#   load  = factor(load, levels = c("Оч. высокий","Высокий","Средний","Слабый")))
# 
# AllData = AllData%>%mutate(load_score = case_when(
#   Site == "BOLOTNAYA"  | Site == "SCHOOL1234" ~ 1,
#   Site == "RUDN"  | Site == "SCHERBINKA" ~ 2,
#   Site == "TROITSK" | Site == "GARDEN" ~ 3,
#   Site == "TIMIRYAZEV" ~ 4))
   
AllData = AllData%>%mutate(load = case_when(
  Site == "TIMIRYAZEV" ~ "Слабый",
  Site == "RUDN" | Site == "TROITSK"  | Site == "GARDEN" ~ "Средний",
  Site == "BOLOTNAYA"  | Site =="SCHOOL1234" | Site == "SCHERBINKA" ~ "Высокий"),
  load  = factor(load, levels = c("Слабый","Средний","Высокий")))

AllData = AllData%>%mutate(load_score = case_when(
  Site == "BOLOTNAYA"  | Site =="SCHOOL1234" | Site == "SCHERBINKA" ~ "3",
  Site == "RUDN" | Site == "TROITSK"  | Site == "GARDEN" ~ "2",
  Site == "TIMIRYAZEV" ~ "1")) 
   
AllData$load_score %>% unique()
AllData$insite_load = "высокий"
AllData$insite_load_score = 2
low_in_site_load_TTlist = c("062",100,102,107,108,110,113,114,115,118,119,122,123,124,129,135,137,
                             140,141,146,149,151,165,168,171,175,188,192,192,198,206,220,221,230,
                             233,238,240,245,283,"077","079","088",104,138,193,210,212,248,255,277,285,
                             "061","063","087","096",112,120,145,158,163,172,176,183,195,203,208,209,218,
                             219,226,246,249,256,259,263,279,282,287,289,291,293)
low_in_site_load_TTlist = paste("218A0",low_in_site_load_TTlist,sep="")                             
AllData$insite_load[AllData$id %in% low_in_site_load_TTlist] = "низкий"
AllData$insite_load_score[AllData$id %in% low_in_site_load_TTlist] = 1


########################### Correcting species names ####################################

AllData$Species[AllData$Species == "Acer platanoides "] = "Acer platanoides"
AllData$Species[AllData$Species == "Fraxinus "] = "Fraxinus excelsior"
AllData$Species[AllData$Species == "Quercus robur "] = "Quercus robur"
AllData$Species[AllData$Species == "Salix  alba"] = "Salix alba"
AllData$Species[AllData$Species == "Larix siberica "] = "Larix sibirica"
AllData$Species[AllData$Species == "Larix decidua"] = "Larix sibirica"
AllData$Species[AllData$Species == "Larix siberica"] = "Larix sibirica"
AllData$Species[AllData$Species == "Tilia cordata "] = "Tilia cordata"
AllData$Species[AllData$Species == "Acer  pseudoplatanus"] = "Acer platanoides"
AllData$Species %>% unique()

############################   GROWTH d#################################################

dis_pred_table = data.frame()
for (ids in AllData$id %>% unique){
  
  dat = AllData%>%filter(id == ids)%>% 
    filter(b_W_860 <10) %>% filter((volt > 3.99 & volt<4.05))
  if(nrow(dat) < 10){next()}
  pred = ggplot_build(ggplot(dat)+
                      geom_smooth(aes(x=doy,y=dist13),method="lm" ,size=.1)+
                      stat_smooth(aes(x=doy,y=dist13),method="lm"))$data[[2]]
  pred_table = data.frame(round(pred$x, digits = 0), pred$y, id = ids, growth = max(pred$y) - pred$y)
  if(pred_table[1,2] < pred_table[length(pred_table[,1]),2]){
    pred_table[,2]=pred_table[1,2]
  }
  if(last(pred_table$growth) < first(pred_table$growth)){
    pred_table$growth=0
  }
  dis_pred_table = rbind(dis_pred_table, pred_table)
}
names(dis_pred_table) = c("doy","dist_pred","id", "growth")
AllData = left_join(AllData, dis_pred_table, by=c("id","doy"))
AllData$growth[is.na(AllData$growth)] = 0
AllData$growth[is.infinite(AllData$growth)] = 0



# VTA = read_delim("VTA.csv", ";", escape_double = FALSE,trim_ws = TRUE)
# VTA$id = paste("218A",VTA$id, sep="")
# VTA = VTA %>%mutate(score = rowMeans(.[2:23], na.rm = T))
# VTAscore =VTA %>% as.data.frame %>% dplyr::select(id, score)
# 
# AllData = left_join(AllData,VTAscore, by="id")


AllData$age_group_index = "I"
AllData$age_group_index[AllData$age_group == 2] = "II"
AllData$age_group_index[AllData$age_group == 3] = "III"
AllData$age_group_index[AllData$age_group == 4] = "IV"
AllData$age_group_index[AllData$age_group == 5] = "V"
AllData$age_group_index[AllData$age_group == 6] = "VI"



###### CREATINF DESCRIPTION TABLE##############


AllDataSummary= AllData %>% group_by(SiteIndex, Species,age_group_index,load,insite_load,id)%>%
  summarise(d = mean(diam),DBH = mean(DBH),DTT = mean(DTT), height = mean(height), VTA = mean(VTAscore))


write.csv(AllDataSummary, file="DB_description.csv")

#AllData2 = AllData2%>%group_by(id)%>%mutate(growth =first(dist_pred)-dist_pred)

# ggplot(AllData2)+
#   geom_point(aes(x=time,y=growth), size=.1)+facet_wrap(~id)+ylim(0,10)+theme_bw()
##############################################################################

writeFluxTSALg = function(AllData){

    plotbunch = AllData%>%group_by(load, Species, doy, id) %>% mutate(update = length(id))%>%
      summarise(sFlux = sum(Flux, na.rm=T), readings = mean(update), diam = mean(diam, na.rm=T), 
                time=mean(time,na.rm=T), load_score = mean(load_score,na.rm=T)) %>%
      mutate(suFlux = sFlux*readings/24) %>%
      group_by(load,Species, doy) %>% summarise(Flux = mean(suFlux, na.rm=T), d = mean(diam), 
                                                time=as.Date(mean(time,na.rm=T)), load_score = mean(load_score,na.rm=T)) %>% 
      group_by(Species)%>%
      do(Flux = ggplot(data = .)
         +geom_smooth(aes(x=time,y=Flux, group = load, color=load, fill = load))
         #+geom_ribbon(aes(x=time,y=Flux, group = load, color=load, se=FALSE))
         +geom_point(aes(x=time,y=Flux, group = load, color=load),size=.1)
         +scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                       limits = c(as.Date("01.06.2019", "%d.%m.%Y"), as.Date("01.10.2019", "%d.%m.%Y")), name = NULL)
         +scale_y_continuous( limits = c(0,75), name = expression(Скорость~" "~сокотечения~" "~л~д^-1))
         +scale_color_lancet(guide=FALSE)
         +scale_fill_lancet(name = "Уровень антропогенной нагрузки")
         +theme_bw()
         +theme(legend.position="bottom")
         
      )
    
    for(i in 1:nrow(plotbunch)){
      filename = paste("Load_anhtrop",plotbunch[i,1],names(plotbunch)[2],".png",sep="_")
      graph = plotbunch[i,2][[1]][[1]]
      ggsave(filename, graph,device = "png",width=8,height=6,units="in")
    } 
}

writeFluxTSALinSg = function(AllData){
  
  plotbunch = AllData%>%group_by(Site, insite_load,Species, doy, id) %>% mutate(update = length(id))%>%
    summarise(sFlux = sum(Flux, na.rm=T), readings = mean(update), diam = mean(diam, na.rm=T), 
              time=mean(time,na.rm=T), load_score = mean(insite_load_score,na.rm=T)) %>%
    mutate(suFlux = sFlux*readings/24) %>%
    group_by(Site,insite_load,Species, doy) %>% summarise(Flux = mean(suFlux, na.rm=T), d = mean(diam), 
                                              time=as.Date(mean(time,na.rm=T)), load_score = mean(load_score,na.rm=T)) %>% 
    group_by(Site,Species)%>%
    do(Flux = ggplot(data = .)
       +geom_smooth(aes(x = time,y = Flux, group = insite_load, color = insite_load, fill = insite_load))
       #+geom_ribbon(aes(x=time,y=Flux, group = load, color=load, se=FALSE))
       +geom_point(aes(x=time,y=Flux, group = insite_load, color = insite_load),size = .1)
       +scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                     limits = c(as.Date("01.06.2019", "%d.%m.%Y"), as.Date("01.10.2019", "%d.%m.%Y")), name = NULL)
       +scale_y_continuous( limits = c(0,75), name = expression(Скорость~" "~сокотечения~" "~л~д^-1))
       +scale_color_lancet(guide=FALSE, )
       +scale_fill_lancet(name = "Уровень антропогенной нагрузки внутри участка")
       +theme_bw()
       +theme(legend.position="bottom")
       
    )
  
  for(i in 1:nrow(plotbunch)){
    filename = paste("Load_antr_in_site_",plotbunch[i,1],plotbunch[i,2],".png",sep="_")
    graph = plotbunch[i,3][[1]][[1]]
    ggsave(filename, graph,device = "png",width=8,height=6,units="in")
  } 
}

writeFluxTSg = function(data, sitename){
  plotbunch = data%>%group_by(Species, doy, id) %>% mutate(update = length(id))%>%
    summarise(sFlux = sum(Flux, na.rm=T), readings = mean(update), diam = mean(diam, na.rm=T), time=mean(time,na.rm=T)) %>%
    mutate(suFlux = sFlux*readings/24) %>%
    group_by(Species, doy) %>% summarise(Flux = mean(suFlux, na.rm=T), d = mean(diam), time=as.Date(mean(time,na.rm=T))) %>% group_by(Species)%>%
    do(Flux = ggplot(data = .)
       +geom_smooth(aes(x=time,y=Flux))
       +geom_point(aes(x=time,y=Flux),size=.1)
       +scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                     limits = c(as.Date("01.05.2019", "%d.%m.%Y"),NA), name = NULL)
       +scale_y_continuous( limits = c(0,75), name = expression(Скорость~" "~сокотечения~" "~л~д^-1))
       +theme_bw()

       )
  
  
  #sitename = "RUDN"
  for(i in 1:nrow(plotbunch)){
    filename = paste(sitename,plotbunch[i,1],names(plotbunch)[2],".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
  } 
}




writeFluxTSTTg = function(data, sitename){
  plotbunch = data%>%group_by(Species, doy, id) %>% mutate(update = length(id))%>%
    summarise(sFlux = sum(Flux, na.rm=T), readings = mean(update), diam = mean(diam, na.rm=T) ,time=mean(time,na.rm=T)) %>%
    mutate(suFlux = sFlux*readings/24) %>%
    group_by(id, doy) %>% summarise(Flux = mean(suFlux, na.rm=T), d = mean(diam),time=mean(time,na.rm=T)) %>% group_by(id)%>%
    do(Flux = ggplot(data = .)
       +geom_smooth(aes(x=as.Date(time),y=Flux))
       +geom_point(aes(x=as.Date(time),y=Flux),size=.1)
       +scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                     limits = c(as.Date("01.05.2019", "%d.%m.%Y"),NA), name = NULL)
       +scale_y_continuous( limits = c(0,75), name = expression(Скорость~" "~сокотечения~" "~л~д^-1))
       +theme_bw()
       +theme_bw())
  
  
  #sitename = "RUDN"
  for(i in 1:nrow(plotbunch)){
    filename = paste(sitename,plotbunch[i,1],names(plotbunch)[2],".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
  } 
}


#plotbunch[15,2][[1]]

writeFluxDiurnalg = function(data, sitename){
  months_n = factor(c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"), 
                    levels = c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"))
  data = data%>%mutate(month = month(time))
  plotbunch = data%>%group_by(Species, hour, month,id) %>% filter(month<11 & month>4)%>%
    summarise(Flux = mean(Flux, na.rm=T)) %>% group_by(Species) %>% 
    mutate(months = months_n[month]) %>%
    do(DiurnalFlux = ggplot(data = .)
       +geom_smooth(aes(x=hour,y=Flux))
       +geom_point(aes(x=hour,y=Flux),size=.1)
       +scale_x_continuous(limits = c(0,24), breaks =c(0,3,6,9,12,15,18,21) ,name = expression(Часы~суток))
       +scale_y_continuous( limits = c(0,10), name = expression(Скорость~" "~сокотечения~" "~л~ч^-1))
       +facet_wrap(~months,nrow=2,ncol=3,strip.position = "bottom" )
       +theme_bw())
  
  
  #sitename = "RUDN"
  for(i in 1:nrow(plotbunch)){
    filename = paste(names(plotbunch)[2],plotbunch[i,1],sitename,".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
  } 
}

writeFluxDiurnalALg = function(AllData){
  
  
  months_n = factor(c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"), 
                    levels = c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"))
  
  AllData = AllData%>%mutate(month = month(time))
  plotbunch = AllData%>%group_by(load,Species, hour, month,id) %>% filter(month<11 & month>4)%>%
    summarise(Flux = mean(Flux, na.rm=T)) %>% group_by(Species) %>% 
    mutate(months = months_n[month]) %>%
    do(DiurnalFlux = ggplot(data = .)
       +geom_smooth(aes(x=hour,y=Flux, group = load, color=load, fill = load))
       +geom_point(aes(x=hour,y=Flux, group = load,color=load),size=.1)
       +scale_x_continuous(limits = c(0,24), breaks =c(0,3,6,9,12,15,18,21) ,name = expression(Часы~суток))
       +scale_y_continuous( limits = c(0,10), name = expression(Скорость~" "~сокотечения~" "~л~ч^-1))
       +facet_wrap(~months,nrow=2,ncol=3,strip.position = "bottom" )
       +scale_color_lancet(guide=FALSE)
       +scale_fill_lancet(name = "Уровень антропогенной нагрузки")
       +theme_bw()
       +theme(legend.position="bottom"))

  for(i in 1:nrow(plotbunch)){
    filename = paste("Load_anhtrop",plotbunch[i,1],names(plotbunch)[2],".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=8,height=6,units="in")
  } 
}


writeFluxDiurnalALinSg = function(AllData){
  
  
  months_n = factor(c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"), 
                    levels = c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"))
  
  AllData = AllData%>%mutate(month = month(time))
  plotbunch = AllData%>%group_by(insite_load,Site,Species, hour, month,id) %>% filter(month<11 & month>4)%>%
    summarise(Flux = mean(Flux, na.rm=T)) %>% group_by(Site,Species) %>% 
    mutate(months = months_n[month]) %>%
    do(DiurnalFlux = ggplot(data = .)
       +geom_smooth(aes(x=hour,y=Flux, group = insite_load, color=insite_load, fill = insite_load))
       +geom_point(aes(x=hour,y=Flux, group = insite_load,color=insite_load),size=.1)
       +scale_x_continuous(limits = c(0,24), breaks =c(0,3,6,9,12,15,18,21) ,name = expression(Часы~суток))
       +scale_y_continuous( limits = c(0,10), name = expression(Скорость~" "~сокотечения~" "~л~ч^-1))
       +facet_wrap(~months,nrow=2,ncol=3,strip.position = "bottom" )
       +scale_color_lancet(guide=FALSE)
       +scale_fill_lancet(name = "Уровень антропогенной нагрузки внутри участка")
       +theme_bw()
       +theme(legend.position="bottom"))
  
  for(i in 1:nrow(plotbunch)){
    filename = paste("Load_anhtrop",plotbunch[i,1],plotbunch[i,2],".png",sep="_")
    graph = plotbunch[i,3][[1]][[1]]
    ggsave(filename, graph,device = "png",width=8,height=6,units="in")
  } 
}

writeFluxDiurnalTTg = function(data, sitename){
  months_n = factor(c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"), 
                    levels = c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"))
  data = data%>%mutate(month = month(time))
  plotbunch = data%>%group_by(Species, hour, month,id) %>% filter(month<11 & month>4)%>%
     group_by(id) %>% mutate(months = months_n[month]) %>%
    do(DiurnalFlux = ggplot(data = .)
       +geom_smooth(aes(x=hour,y=Flux))
       +geom_point(aes(x=hour,y=Flux),size=.1)
       +scale_x_continuous(limits = c(0,24), breaks =c(0,3,6,9,12,15,18,21) ,name = expression(Часы~суток))
       +scale_y_continuous( limits = c(0,10), name = expression(Скорость~" "~сокотечения~" "~л~ч^-1))
       +facet_wrap(~months,nrow=2,ncol=3,strip.position = "bottom" )
       +theme_bw())
  
  
  #sitename = "RUDN"
  for(i in 1:nrow(plotbunch)){
    filename = paste(names(plotbunch)[2],plotbunch[i,1],sitename,".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
  } 
}


#plotbunch[5,2][[1]]

writeNdviTSg = function(data, sitename){
  
  plotbunch = data%>%group_by(Species, doy, id) %>% filter(NDVI >0 & NDVI <1)%>%
    summarise(dNDVI = mean(NDVI, na.rm=T), ndvi_med = quantile(NDVI,0.5,na.rm=T),
              ndvi_max = quantile(NDVI,0.95,na.rm=T), ndvi_v = NDVI[which.max(VPD)],
               ndvi_l = NDVI[which.max(b_G_550)], time = mean(time, na.rm = T)) %>%na.omit()%>%filter(!out_of_two_sigma(dNDVI))%>%
     group_by(Species) %>%
    do(NDVI = ggplot(data = .)
       +geom_smooth(aes(x=as.Date(time),y=ndvi_max), method="loess", span=.8)
       +geom_point(aes(x=as.Date(time),y=ndvi_max),size=.1, alpha=1/10)
       +scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                     limits = c(as.Date("01.05.2019", "%d.%m.%Y"),as.Date("01.10.2019", "%d.%m.%Y")), name = NULL)
       +scale_y_continuous( limits = c(0,1), name = expression(Вегетационный~" "~индекс~" "~NDVI))
       +theme_bw())
  
  
  #sitename = "RUDN"
  for(i in 1:nrow(plotbunch)){
    filename = paste(names(plotbunch)[2],plotbunch[i,1],sitename,".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
  } 
}

#plotbunch[5,2][[1]]
writeNdviTSTTg = function(data, sitename){
  
  plotbunch = data%>%group_by(Species, doy, id) %>% filter(NDVI >0 & NDVI <0.97)%>%
    summarise(dNDVI = mean(NDVI, na.rm=T), ndvi_med = quantile(NDVI,0.5,na.rm=T),
              ndvi_max = quantile(NDVI,0.9,na.rm=T), ndvi_v = NDVI[which.max(VPD)],
              ndvi_l = NDVI[which.max(b_G_550)], time = mean(time, na.rm = T)) %>%na.omit()%>%filter(!out_of_two_sigma(dNDVI))%>%
    group_by(id) %>%
    do(NDVI = ggplot(data = .)
       +geom_smooth(aes(x=as.Date(time),y=ndvi_max), method="loess", span=1)
       +geom_point(aes(x=as.Date(time),y=ndvi_max),size=.1, alpha=1/10)
       +scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                     limits = c(as.Date("01.05.2019", "%d.%m.%Y"),as.Date("01.10.2019", "%d.%m.%Y")), name = NULL)
       +scale_y_continuous( limits = c(0,1), name = expression(Вегетационный~" "~индекс~" "~NDVI))
       +theme_bw())
  
  
  #sitename = "RUDN"
  for(i in 1:nrow(plotbunch)){
    filename = paste(names(plotbunch)[2],plotbunch[i,1],sitename,".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
  } 
}


writeNdviTSALg = function(data, sitename){
  
  plotbunch = data%>%group_by(load,Species, doy, id) %>% filter(NDVI >0 & NDVI <0.97)%>%
    summarise(dNDVI = mean(NDVI, na.rm=T), ndvi_med = quantile(NDVI,0.5,na.rm=T),
              ndvi_m = quantile(NDVI,0.9,na.rm=T), ndvi_v = NDVI[which.max(VPD)],
              ndvi_l = NDVI[which.max(b_G_550)], time = mean(time, na.rm = T)) %>%na.omit()%>%filter(!out_of_two_sigma(ndvi_m))%>%
    group_by(Species) %>%
    do(NDVI = ggplot(data = .)
       +geom_smooth(aes(x=as.Date(time),y=ndvi_m, color=load, fill = load), method="loess", span=.4)
       +geom_point(aes(x=as.Date(time),y=ndvi_m, color=load), size=.1, alpha=1/10)
       +scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                     limits = c(as.Date("01.06.2019", "%d.%m.%Y"),as.Date("01.10.2019", "%d.%m.%Y")), name = NULL)
       +scale_y_continuous( limits = c(0,1), name = expression(Вегетационный~" "~индекс~" "~NDVI))
       +scale_color_lancet(guide=FALSE)
       +scale_fill_lancet(name = "Уровень антропогенной нагрузки")
       +theme_bw()
       +theme(legend.position="bottom")
       
    )


    for(i in 1:nrow(plotbunch)){
      filename = paste("Load_anhtrop",plotbunch[i,1],names(plotbunch)[2],".png",sep="_")
      graph = plotbunch[i,2][[1]][[1]]
      ggsave(filename, graph,device = "png",width=8,height=6,units="in")
    } 

}


writeNdviTSALinSg = function(data, sitename){
  
  plotbunch = data%>%group_by(insite_load,Site,Species, doy, id) %>% filter(NDVI >0 & NDVI <0.97)%>%
    summarise(dNDVI = mean(NDVI, na.rm=T), ndvi_med = quantile(NDVI,0.5,na.rm=T),
              ndvi_m = quantile(NDVI,0.9,na.rm=T), ndvi_v = NDVI[which.max(VPD)],
              ndvi_l = NDVI[which.max(b_G_550)], time = mean(time, na.rm = T)) %>%na.omit()%>%filter(!out_of_two_sigma(ndvi_m))%>%
    group_by(Site,Species) %>%
    do(NDVI = ggplot(data = .)
       +geom_smooth(aes(x=as.Date(time),y=ndvi_m, color=insite_load, group  = insite_load, fill = insite_load),
                    method="loess", span=.9)
       +geom_point(aes(x=as.Date(time),y=ndvi_m, color=insite_load), size=.1, alpha=1/10)
       +scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                     limits = c(as.Date("01.06.2019", "%d.%m.%Y"),as.Date("01.10.2019", "%d.%m.%Y")), name = NULL)
       +scale_y_continuous( limits = c(0,1), name = expression(Вегетационный~" "~индекс~" "~NDVI))
       +scale_color_lancet(guide=FALSE)
       +scale_fill_lancet(name = "Уровень антропогенной нагрузки")
       +theme_bw()
       +theme(legend.position="bottom")
       
    )
  
  
  for(i in 1:nrow(plotbunch)){
    filename = paste("Load_anhtrop_in_site_NDVI",plotbunch[i,1],plotbunch[i,2],".png",sep="_")
    graph = plotbunch[i,3][[1]][[1]]
    ggsave(filename, graph,device = "png",width=8,height=6,units="in")
  } 
  
}



writePRITSALg = function(data, sitename){
  
  plotbunch = data%>%group_by(load,Species, doy, id) %>% filter(NDVI >0 & NDVI <0.97)%>%
    summarise(dNDVI = mean(NDVI, na.rm=T), ndvi_med = quantile(NDVI,0.5,na.rm=T),
              PRI_m = quantile(( b_O_600- b_B_500)/( b_O_600 + b_B_500),0.1,na.rm=T), ndvi_v = NDVI[which.max(VPD)],
              ndvi_l = NDVI[which.max(b_G_550)], time = mean(time, na.rm = T)) %>%na.omit()%>%filter(!out_of_two_sigma(PRI_m))%>%
    group_by(Species) %>%
    do(PRI = ggplot(data = .)
       +geom_smooth(aes(x=as.Date(time),y=PRI_m, color=load, fill = load), method="loess", span=.4)
       +geom_point(aes(x=as.Date(time),y=PRI_m, color=load), size=.1, alpha=1/10)
       +scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                     limits = c(as.Date("01.06.2019", "%d.%m.%Y"),as.Date("01.10.2019", "%d.%m.%Y")), name = NULL)
       +scale_y_continuous( limits = c(-0.25,0.25), name = expression(Минимальное~" "~значение~" "~индекса~" "~PRI~" "~за~" "~день))
       +scale_color_lancet(guide=FALSE)
       +scale_fill_lancet(name = "Уровень антропогенной нагрузки")
       +theme_bw()
       +theme(legend.position="bottom")
       
    )
  
  
  for(i in 1:nrow(plotbunch)){
    filename = paste("Load_anhtrop",plotbunch[i,1],names(plotbunch)[2],".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=8,height=6,units="in")
  } 
  
}


writePRITSALinSg = function(data, sitename){
  
  plotbunch = data%>%group_by(insite_load,Site,Species, doy, id) %>% filter(NDVI >0 & NDVI <0.97)%>%
    summarise(dNDVI = mean(NDVI, na.rm=T), ndvi_med = quantile(NDVI,0.5,na.rm=T),
              PRI_m = quantile(( b_O_600- b_B_500)/( b_O_600 + b_B_500),0.1,na.rm=T), ndvi_v = NDVI[which.max(VPD)],
              ndvi_l = NDVI[which.max(b_G_550)], time = mean(time, na.rm = T)) %>%na.omit()%>%filter(!out_of_two_sigma(PRI_m))%>%
    group_by(Site,Species) %>%
    do(PRI = ggplot(data = .)
       +geom_smooth(aes(x=as.Date(time),y=PRI_m, color=load, fill = load), method="loess", span=.4)
       +geom_point(aes(x=as.Date(time),y=PRI_m, color=load), size=.1, alpha=1/10)
       +scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                     limits = c(as.Date("01.06.2019", "%d.%m.%Y"),as.Date("01.10.2019", "%d.%m.%Y")), name = NULL)
       +scale_y_continuous( limits = c(-0.25,0.25), name = expression(Минимальное~" "~значение~" "~индекса~" "~PRI~" "~за~" "~день))
       +scale_color_lancet(guide=FALSE)
       +scale_fill_lancet(name = "Уровень антропогенной нагрузки внутри участка")
       +theme_bw()
       +theme(legend.position="bottom")
       
    )
  
  
  for(i in 1:nrow(plotbunch)){
    filename = paste("Load_anhtrop_insite_PRI_",plotbunch[i,1],plotbunch[i,2],".png",sep="_")
    graph = plotbunch[i,3][[1]][[1]]
    ggsave(filename, graph,device = "png",width=8,height=6,units="in")
  } 
  
}



#plotbunch[5,2][[1]]

writeAngleTSg = function(data, sitename){
data$phi = data$phi+180
data$psi = data$psi+180
data$theta = data$theta+180
  plotbunch = data%>%group_by(Species, doy, id) %>% 
    summarise(angle = mean(psi, na.rm=T), time = mean(time, na.rm = T)) %>%na.omit()%>%filter(!out_of_two_sigma(angle))%>%
    group_by(Species) %>%
    do(angle = ggplot(data = .)
       +geom_smooth(aes(x=as.Date(time),y=angle), method="loess", span=.2)
       +geom_point(aes(x=as.Date(time),y=angle),size=.1, alpha=1/10)
       +scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                     limits = c(as.Date("01.05.2019", "%d.%m.%Y"),NA), name = NULL)
       +scale_y_continuous(  name = expression(Угол~" "~уклона~" "~дерева))
       +theme_bw())
  
  
  #sitename = "RUDN"
  for(i in 1:nrow(plotbunch)){
    filename = paste(names(plotbunch)[2],plotbunch[i,1],sitename,".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
  } 
}



writeNHzTSg = function(data, sitename){
  
  plotbunch = data%>%group_by(Species, doy, id) %>% 
    summarise(W = mean((46000-Hz)/(Hz+46000)*50, na.rm=T),  time = mean(time, na.rm = T)) %>% na.omit() %>%
    group_by(Species) %>%
    do(NHz50 = ggplot(data = .)
       +geom_smooth(aes(x=as.Date(time),y= W), method="loess", span=.2)
       +geom_point (aes(x=as.Date(time), y= W, color=id), size=.1, alpha=1/3)
       +scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                     limits = c(as.Date("01.05.2019", "%d.%m.%Y"),NA), name = NULL)
       +scale_y_continuous(limits = c(0,50),  name = expression(Нормализованная~" "~влажность~" "~древесины))
       +theme_bw()
       +theme(legend.position = "none") )
  
  
  #sitename = "RUDN"
  for(i in 1:nrow(plotbunch)){
    filename = paste(names(plotbunch)[2],plotbunch[i,1],sitename,".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
  } 
}



writeTairRhTSg = function(data, sitename){
  
  plotbunch = data%>%group_by(Species) %>%filter(!is.na(tair))%>%
    do(clim = ggplot(data = .)
       +geom_line(aes(x=as.Date(time),y=tair),size=.2, alpha=1/3)
       +geom_line(aes(x=as.Date(time),y=VPD*20),size=.2, color=3, alpha=1/3)
       +scale_y_continuous(name = expression(Температура~воздуха~" "~C),
                          sec.axis = sec_axis(~./50, name = "Отрицательное давление паров влаги, кПa", labels = function(b) { round(b * 1, 2)}),
                          limits = c(0,40))
       +scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                     limits = c(as.Date("01.05.2019", "%d.%m.%Y"),NA), name = NULL)
      +theme_bw()
    )
  
  #sitename = "RUDN"
  for(i in 1:nrow(plotbunch)){
    filename = paste(names(plotbunch)[2],plotbunch[i,1],sitename,".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
  } 
}


writeTairRhTSAlg = function(data){
  
  plotbunch = data%>%group_by(Species) %>%filter(!is.na(tair))%>%
    do(clim = ggplot(data = .)
       +geom_point(aes(x=as.Date(time),y=tair, group = load, color = load),size=.2, alpha=1/3)
       +geom_smooth(aes(x=as.Date(time),y=tair, group = load, color=load, fill = load),method = "loess",span = .4)
       +geom_line(aes(x=as.Date(time),y=VPD*20, group = load),size=.3, color=5, alpha=1/5)
       +scale_y_continuous(name = expression(Температура~воздуха~" "~C),
                           sec.axis = sec_axis(~./50, name = "Отрицательное давление паров влаги, кПa", labels = function(b) { round(b * 1, 2)}),
                           limits = c(0,40))
       +scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                     limits = c(as.Date("01.05.2019", "%d.%m.%Y"),as.Date("01.10.2019", "%d.%m.%Y")), name = NULL)
       +scale_color_lancet(guide=FALSE)
       +scale_fill_lancet(name = "Уровень антропогенной нагрузки внутри участка")
       +theme_bw()
       +theme(legend.position="bottom")
    )
  
  #sitename = "RUDN"
  for(i in 1:nrow(plotbunch)){
    filename = paste("Ant_load",names(plotbunch)[2],plotbunch[i,1],".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
  } 
}


#data=RUDNdata[[2]]
#plotbunch[1,2][[1]]


writeAngleDeviation = function(data, sitename){
  data = data %>% group_by(doy,id) %>% mutate(psi_d = mean(psi, na.rm = T),
                                              phi_d = mean(phi, na.rm = T), 
                                              theta_d = mean(theta, na.rm = T))
  
  data = data %>% group_by(Species) %>% mutate(mxt=max(theta_d-theta, na.rm=T),
                                   mnt=min(theta_d-theta, na.rm=T))
  data = data %>% group_by(doy, id) %>%
    mutate(dtheta  = (theta- theta_d)) %>% ungroup%>% group_by( Species) %>%
    mutate(mxt=max(dtheta , na.rm=T), mnt=min(dtheta , na.rm=T)) %>% group_by(doy, Species) %>%
    mutate(mdtheta = mean(dtheta)) 
  
  plotbunch = data%>%group_by(Species) %>%
    do(stability = ggplot(data = .)+
  geom_line(aes(x=as.Date(time),y=dtheta ), color=1, size=0.02)+
  geom_hline(aes(yintercept=mxt), color=2,linetype="dashed", size=.02)+
  geom_hline(aes(yintercept=mnt), color=2,linetype="dashed", size=.02)+
  scale_y_continuous(name = expression(Отклонение~от~среднесуточного~значения~угла~theta~','~градусы), limits=c(-5,5))+
  scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                  limits = c(as.Date("01.05.2019", "%d.%m.%Y"),NA), name = NULL)+
  theme_bw()
    )
#geom_smooth(aes(x=time,y=theta_d-theta ), color=3, size=0.02, se=T, span=.1,method = "loess")+
#scale_y_continuous(limits=c(-10,10))+

  for(i in 1:nrow(plotbunch)){
    filename = paste(names(plotbunch)[2],plotbunch[i,1],sitename,".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
  } 
}

#data=RUDNdata[[2]]
#plotbunch[21,2][[1]]


writeAngleDeviationTT = function(data, sitename){
  data = data %>% group_by(doy,id) %>% mutate(psi_d = mean(psi, na.rm = T),
                                              phi_d = mean(phi, na.rm = T), 
                                              theta_d = mean(theta, na.rm = T)) %>%
    mutate(dtheta  = (theta- theta_d)) %>%ungroup()%>%filter(!out_of_two_sigma(dtheta))%>%
    filter(dtheta <5 & dtheta > -5)%>%group_by(id) %>% mutate(mxt=max(dtheta, na.rm=T),
                                                  mnt=min(dtheta, na.rm=T))
  
  plotbunch = data%>%group_by(id) %>% 
    do(stability = ggplot(data = .)+
         geom_line(aes(x=as.Date(time),y=dtheta ), color=1, size=0.02)+
         geom_hline(aes(yintercept=mean(mxt,na.rm = T)), color=2,linetype="dashed", size=.02)+
         geom_hline(aes(yintercept=mean(mnt,na.rm = T)), color=2,linetype="dashed", size=.02)+
         scale_y_continuous(name = expression(Отклонение~от~среднесуточного~значения~угла~theta~','~градусы), limits=c(-5,5))+
         scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                      limits = c(as.Date("01.05.2019", "%d.%m.%Y"),NA), name = NULL)+
         theme_bw()
    )
  #geom_smooth(aes(x=time,y=theta_d-theta ), color=3, size=0.02, se=T, span=.1,method = "loess")+
  #scale_y_continuous(limits=c(-10,10))+
  
  for(i in 1:nrow(plotbunch)){
    filename = paste(names(plotbunch)[2],plotbunch[i,1],sitename,".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
  } 
}



#data=RUDNdata[[2]]
#plotbunch[21,2][[1]]

writeZ2TT = function(data, sitename,meteo_data){
  data = left_join(data,meteo_data, by=c("year","doy","hour"))
  data = data %>% group_by(doy,id) %>%
    mutate(z2 = max(gz2+gy2+gx2, na.rm = T),
           WS = max(WS, na.rm = T))
  
  plotbunch = data%>%group_by(id) %>%
    do(AnglStdDevWspeed = ggplot(data = .)+
         geom_line(aes(x=as.Date(time),y=z2 ), color=1, size=0.02)+
         geom_line(aes(x=as.Date(time),y=WS/1000000), color=2,linetype="dashed", size=.02)+
         scale_y_continuous(name = expression(Cуммы~стандартных~отклонений~цифрового~сигнала~акслерометра~по~трем~осям),
                            sec.axis = sec_axis(~.*1000000, name = "Максимальная скорость ветра за последние 3 часа, м с^-1", 
                                                labels = function(b) { round(b * 1, 2)}))+
         scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                      limits = c(as.Date("01.05.2019", "%d.%m.%Y"),NA), name = NULL)+
         theme_bw()
    )
  #geom_smooth(aes(x=time,y=theta_d-theta ), color=3, size=0.02, se=T, span=.1,method = "loess")+
  #scale_y_continuous(limits=c(-10,10))+
  
  for(i in 1:nrow(plotbunch)){
    filename = paste(names(plotbunch)[2],plotbunch[i,1],sitename,".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
  } 
}

writeZ2TTh = function(data, sitename,meteo_data){
  data = left_join(data,meteo_data, by=c("year","doy","hour"))
  data = data %>% mutate(g2 = gz2+gy2+gx2)
  plotbunch = data%>%group_by(id) %>%
    do(g2vsWSpeed = ggplot(data = .)+
         geom_line(aes(x=as.Date(time),y=g2 ), color=1, size=0.02)+
         geom_line(aes(x=as.Date(time),y=WS/1000000), color=2,linetype="dashed", size=.02)+
         scale_y_continuous(name = expression(Cуммы~стандартных~отклонений~цифрового~сигнала~акслерометра~по~трем~осям),
                            sec.axis = sec_axis(~.*1000000, name = "Максимальная скорость ветра за последние 3 часа, м с^-1", 
                                                labels = function(b) { round(b * 1, 2)}))+
         scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                      limits = c(as.Date("01.05.2019", "%d.%m.%Y"),NA), name = NULL)+
         theme_bw()
    )
  #geom_smooth(aes(x=time,y=theta_d-theta ), color=3, size=0.02, se=T, span=.1,method = "loess")+
  #scale_y_continuous(limits=c(-10,10))+
  
  for(i in 1:nrow(plotbunch)){
    filename = paste(names(plotbunch)[2],plotbunch[i,1],sitename,".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    try(ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in"),T)
  } 
}


#data=RUDNdata[[2]]
#plotbunch[1,2][[1]]

writeZ2 = function(data, sitename,meteo_data){
  data = left_join(data,meteo_data, by=c("year","doy","hour"))
  data = data %>% group_by(doy,id,Species) %>%
    mutate(z2 = max(gz2+gy2+gx2, na.rm = T),
           WS = max(WS, na.rm = T))%>%
    group_by(doy,Species)%>%
    mutate(
             z2s = mean(z2, na.rm = T), 
             WSs = mean(WS, na.rm = T)
          )
  
  plotbunch = data%>%group_by(Species)%>%
    do(AnglStdDevWspeed = ggplot(data = .)+
         geom_line(aes(x=as.Date(time),y=z2s ), color=1, size=0.02)+
         geom_line(aes(x=as.Date(time),y=WSs/1000000), color=2,linetype="dashed", size=.02)+
         scale_y_continuous(name = expression(Cуммы~стандартных~отклонений~цифрового~сигнала~акслерометра~по~трем~осям),
                            sec.axis = sec_axis(~.*1000000, name = "Максимальная скорость ветра за последние 3 часа, м с^-1", 
                                                labels = function(b) { round(b * 1, 2)}))+
         scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                      limits = c(as.Date("01.05.2019", "%d.%m.%Y"),NA), name = NULL)+
         theme_bw()
    )
  #geom_smooth(aes(x=time,y=theta_d-theta ), color=3, size=0.02, se=T, span=.1,method = "loess")+
  #scale_y_continuous(limits=c(-10,10))+
  
  for(i in 1:nrow(plotbunch)){
    filename = paste(names(plotbunch)[2],plotbunch[i,1],sitename,".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
  } 
}

writeZ2ALg = function(data,meteo_data){
  
  data = left_join(data,meteo_data, by=c("year","doy","hour"))
  data = data %>% group_by(doy,id,Species,load) %>%
    mutate(z2 = max(gz2+gy2+gx2, na.rm = T),
           WS = max(WS, na.rm = T))%>%
    group_by(doy,Species,load)%>%
    mutate(
      z2s = mean(z2, na.rm = T), 
      WSs = mean(WS, na.rm = T)
    )
  
  plotbunch = data%>%group_by(Species)%>%
    do(trembling = ggplot(data = .)+
         geom_line(aes(x=as.Date(time),y=z2s, color=load ), size=.5)+
         geom_line(aes(x=as.Date(time),y=WSs/5000000), color=2, size=.5)+
         scale_y_continuous(name = expression(Cуммы~стандартных~отклонений~сигнала~акслерометра~по~трем~осям),
                            limits = c(0,5*10^-6),
                            sec.axis = sec_axis(~.*5000000, name = expression(Максимальная~скорость~ветра~за~последние~"3 часа,"~м~с^-1), 
                                                labels = function(b) { round(b * 1, 2)}))+
         scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                      limits = c(as.Date("01.06.2019", "%d.%m.%Y"),as.Date("01.10.2019", "%d.%m.%Y")), name = NULL)+
        scale_color_lancet(name = "Уровень антропогенной нагрузки")+
        theme_bw()+
        theme(legend.position="bottom")
    )
  
  for(i in 1:nrow(plotbunch)){
    filename = paste("Load_anhtrop",plotbunch[i,1],names(plotbunch)[2],".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=8,height=6,units="in")
  } 
  
}

writeZ2ALinSg = function(data,meteo_data){
  
  #data = left_join(data,meteo_data, by=c("year","doy","hour"))
  data = data %>% group_by(doy,id,Site,Species,insite_load) %>%
    mutate(z2 = max(gz2+gy2+gx2, na.rm = T),
           WS = max(WS, na.rm = T))%>%
    group_by(doy,Species,Site,insite_load)%>%
    mutate(
      z2s = mean(z2, na.rm = T), 
      WSs = mean(WS, na.rm = T)
    )
  
  plotbunch = data%>%group_by(Site,Species)%>%
    do(trembling = ggplot(data = .)+
         geom_line(aes(x=as.Date(time),y=z2s, color=insite_load ), size=.5)+
         geom_line(aes(x=as.Date(time),y=WSs/5000000 ),linetype = 4, color=3, size=.2)+
         scale_y_continuous(name = expression(Cуммы~стандартных~отклонений~сигнала~акслерометра~по~трем~осям),
                            limits = c(0,5*10^-6),
                            sec.axis = sec_axis(~.*5000000, name = expression(Максимальная~скорость~ветра~за~последние~"3 часа,"~м~с^-1), 
                                                labels = function(b) { round(b * 1, 2)}))+
         scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                      limits = c(as.Date("01.06.2019", "%d.%m.%Y"),as.Date("01.10.2019", "%d.%m.%Y")), name = NULL)+
         scale_color_lancet(name = "Уровень антропогенной нагрузки")+
         theme_bw()+
         theme(legend.position="bottom")
    )
  
  for(i in 1:nrow(plotbunch)){
    filename = paste("Load_anhtrop_insite_tremble_",plotbunch[i,1],plotbunch[i,2],".png",sep="_")
    graph = plotbunch[i,3][[1]][[1]]
    ggsave(filename, graph,device = "png",width=8,height=6,units="in")
  } 
  
}


writeGrowthTTm = function(Alldata){
  months_n = factor(c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"), 
                    levels = c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"))
  for(sitename in Alldata$Site %>% unique){
    data  = Alldata %>% filter(Site == sitename)
    dat = data %>% group_by(id, month) %>% summarise(growth = max(growth, na.rm=T))
    plotbunch = dat%>%group_by(id) %>%
      do(Growth = ggplot(data = .)+
           geom_col(aes(x=months_n[month],y=growth ), color=1, size=0.02)+
           scale_y_continuous(name = expression(Прирост~даметра~ствола~", "~мм))+
           theme_bw()
      )
    #geom_smooth(aes(x=time,y=theta_d-theta ), color=3, size=0.02, se=T, span=.1,method = "loess")+
    #scale_y_continuous(limits=c(-10,10))+
    
    for(i in 1:nrow(plotbunch)){
      filename = paste(names(plotbunch)[2],plotbunch[i,1],sitename,".png",sep="_")
      graph = plotbunch[i,2][[1]][[1]]
      ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
    } 
  }

}


writeGrowthSpm = function(Alldata){
  months_n = factor(c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"), 
                    levels = c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"))
  for(sitename in Alldata$Site %>% unique){
    data  = Alldata %>% filter(Site == sitename)
    dat = data %>% group_by(id, Species,month) %>% 
      summarise(growth = max(growth, na.rm=T)) %>% group_by(Species,month) %>%
      summarise(growth = mean(growth, na.rm=T))
    plotbunch = dat%>%group_by(Species) %>%
      do(Growth = ggplot(data = .)+
           geom_col(aes(x=months_n[month],y=growth ), color=1, size=0.02)+
           scale_y_continuous(name = expression(Прирост~даметра~ствола~", "~мм))+
           scale_x_discrete(limits = c("Июнь","Июль","Август","Сентябрь"), name = NULL)+
           scale_color_lancet(guide=FALSE)+
           theme_bw()
      )
    #geom_smooth(aes(x=time,y=theta_d-theta ), color=3, size=0.02, se=T, span=.1,method = "loess")+
    #scale_y_continuous(limits=c(-10,10))+
    
    for(i in 1:nrow(plotbunch)){
      filename = paste(names(plotbunch)[2],plotbunch[i,1],sitename,".png",sep="_")
      graph = plotbunch[i,2][[1]][[1]]
      ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
    } 
  }
  
}


writGrowthALSpm = function(Alldata){
  
     months_n = factor(c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"), 
                    levels = c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"))
    data  = Alldata 
    dat = data %>% group_by(id, Species,load,month) %>% 
      summarise(growth = max(growth, na.rm=T)) %>% group_by(load,Species,month) %>%
      summarise(growth = mean(growth, na.rm=T))
    plotbunch = dat%>%group_by(Species) %>%
      do(Growth = ggplot(data = .)+
           geom_col(aes(x=months_n[month],y=growth, fill=load, group = load ), size=0.02, position = "dodge")+
           scale_y_continuous(name = expression(Прирост~даметра~ствола~", "~мм))+
           scale_x_discrete(limits = c("Июнь","Июль","Август","Сентябрь"), name = NULL)+
           scale_color_lancet(guide=FALSE)+
           scale_fill_lancet(name = "Уровень антропогенной нагрузки")+
           theme_bw()+
           theme(legend.position="bottom"))

  
  for(i in 1:nrow(plotbunch)){
    filename = paste("Load_anhtrop",plotbunch[i,1],names(plotbunch)[2],".png",sep="_")
    graph = plotbunch[i,2][[1]][[1]]
    ggsave(filename, graph,device = "png",width=8,height=6,units="in")
  } 
}  

writGrowthALSinSpm = function(Alldata){
  
  months_n = factor(c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"), 
                    levels = c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"))
  data  = Alldata 
  dat = data %>% group_by(id, Species,insite_load,Site,month) %>% 
    summarise(growth = max(growth, na.rm=T)) %>% group_by(insite_load,Site,Species,month) %>%
    summarise(growth = mean(growth, na.rm=T))
  plotbunch = dat%>%group_by(Site,Species) %>%
    do(Growth = ggplot(data = .)+
         geom_col(aes(x=months_n[month],y=growth, fill=insite_load, group = insite_load ), size=0.02, position = "dodge")+
         scale_y_continuous(name = expression(Прирост~даметра~ствола~", "~мм))+
         scale_x_discrete(limits = c("Июнь","Июль","Август","Сентябрь"), name = NULL)+
         scale_color_lancet(guide=FALSE)+
         scale_fill_lancet(name = "Уровень антропогенной нагрузки")+
         theme_bw()+
         theme(legend.position="bottom"))
  
  
  for(i in 1:nrow(plotbunch)){
    filename = paste("Load_anhtrop_insite_growth_",plotbunch[i,1],plotbunch[i,2],".png",sep="_")
    graph = plotbunch[i,3][[1]][[1]]
    ggsave(filename, graph,device = "png",width=8,height=6,units="in")
  } 
} 


           # months_n = factor(c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"), 
           #                   levels = c("Ягварь","Февраль","Март","Апрель","Май","Июнь", "Июль","Август","Сентябрь", "Октябрь","Ноябрь","Декабрь"))
           # 
           #   AllData = AllData%>%mutate(month = month(time))
           #   plotbunch = AllData%>%group_by(load,Species, hour, month,id) %>% filter(month<11 & month>4)%>%
           #     summarise(Flux = mean(Flux, na.rm=T)) %>% group_by(Species) %>% 
           #     mutate(months = months_n[month]) %>%
           #     do(DiurnalFlux = ggplot(data = .)
           #        +geom_smooth(aes(x=hour,y=Flux, group = load, color=load, fill = load))
           #        +geom_point(aes(x=hour,y=Flux, group = load,color=load),size=.1)
           #        +scale_x_continuous(limits = c(0,24), breaks =c(0,3,6,9,12,15,18,21) ,name = expression(Часы~суток))
           #        +scale_y_continuous( limits = c(0,10), name = expression(Скорость~" "~сокотечения~" "~л~ч^-1))
           #        +facet_wrap(~months,nrow=2,ncol=3,strip.position = "bottom" )
           #        +scale_color_viridis_d(guide=FALSE)
           #        +scale_fill_viridis_d(name = "Уровень антропогенной нагрузки")
           #        +theme_bw()
           #        +theme(legend.position="bottom"))





#plotbunch[6,2][[1]]




writeTairRhTSAlg(AllData)

writeGrowthTTm(AllData)
writeGrowthSpm(AllData)
writGrowthALSpm(AllData)
writGrowthALSinSpm(AllData)
writeZ2ALinSg(AllData, meteo_data)

writeFluxTSALg(AllData)
writeFluxTSALinSg(AllData)
writeFluxDiurnalALg(AllData)
writeFluxDiurnalALinSg (AllData)
writeNdviTSALg(AllData)
writeNdviTSALinSg(AllData)
writePRITSALg(AllData)
writePRITSALinSg(AllData)
writeZ2ALg(AllData, meteo_data)


writeFluxTSg(RUDNdata[[2]],"RUDN")
writeFluxTSg(TIMdata[[2]],"Timiryazev")
writeFluxTSg(BLTNdata[[2]],"BOLOTNAYA")
writeFluxTSg(HORTdata[[2]],"GARDEN")
writeFluxTSg(TRSKdata[[2]],"TROITSK")
writeFluxTSg(SCHLdata[[2]],"SCHOOL1234")
writeFluxTSg(SHERdata[[2]],"SCHERBINKA")


writeFluxTSTTg(RUDNdata[[2]],"RUDN")
writeFluxTSTTg(TIMdata[[2]],"Timiryazev")
writeFluxTSTTg(BLTNdata[[2]],"BOLOTNAYA")
writeFluxTSTTg(HORTdata[[2]],"GARDEN")
writeFluxTSTTg(TRSKdata[[2]],"TROITSK")
writeFluxTSTTg(SCHLdata[[2]],"SCHOOL1234")
writeFluxTSTTg(SHERdata[[2]],"SCHERBINKA")


writeFluxDiurnalg(RUDNdata[[2]],"RUDN")
writeFluxDiurnalg(TIMdata[[2]],"Timiryazev")
writeFluxDiurnalg(BLTNdata[[2]],"BOLOTNAYA")
writeFluxDiurnalg(HORTdata[[2]],"GARDEN")
writeFluxDiurnalg(TRSKdata[[2]],"TROITSK")
writeFluxDiurnalg(SCHLdata[[2]],"SCHOOL1234")
writeFluxDiurnalg(SHERdata[[2]],"SCHERBINKA")


writeFluxDiurnalTTg(RUDNdata[[2]],"RUDN")
writeFluxDiurnalTTg(TIMdata[[2]],"Timiryazev")
writeFluxDiurnalTTg(BLTNdata[[2]],"BOLOTNAYA")
writeFluxDiurnalTTg(HORTdata[[2]],"GARDEN")
writeFluxDiurnalTTg(TRSKdata[[2]],"TROITSK")
writeFluxDiurnalTTg(SCHLdata[[2]],"SCHOOL1234")
writeFluxDiurnalTTg(SHERdata[[2]],"SCHERBINKA")




writeNdviTSg(RUDNdata[[2]],"RUDN")
writeNdviTSg(TIMdata[[2]],"Timiryazev")
writeNdviTSg(BLTNdata[[2]],"BOLOTNAYA")
writeNdviTSg(HORTdata[[2]],"GARDEN")
writeNdviTSg(TRSKdata[[2]],"TROITSK")
writeNdviTSg(SCHLdata[[2]],"SCHOOL1234")
writeNdviTSg(SHERdata[[2]],"SCHERBINKA")


writeNdviTSTTg(RUDNdata[[2]],"RUDN")
writeNdviTSTTg(TIMdata[[2]],"Timiryazev")
writeNdviTSTTg(BLTNdata[[2]],"BOLOTNAYA")
writeNdviTSTTg(HORTdata[[2]],"GARDEN")
writeNdviTSTTg(TRSKdata[[2]],"TROITSK")
writeNdviTSTTg(SCHLdata[[2]],"SCHOOL1234")
writeNdviTSTTg(SHERdata[[2]],"SCHERBINKA")


writeAngleTSg(RUDNdata[[2]],"RUDN")
writeAngleTSg(TIMdata[[2]],"Timiryazev")
writeAngleTSg(BLTNdata[[2]],"BOLOTNAYA")
writeAngleTSg(HORTdata[[2]],"GARDEN")
writeAngleTSg(TRSKdata[[2]],"TROITSK")
writeAngleTSg(SCHLdata[[2]],"SCHOOL1234")
writeAngleTSg(SHERdata[[2]],"SCHERBINKA")

writeNHzTSg(RUDNdata[[2]],"RUDN")
writeNHzTSg(TIMdata[[2]],"Timiryazev")
writeNHzTSg(BLTNdata[[2]],"BOLOTNAYA")
writeNHzTSg(HORTdata[[2]],"GARDEN")
writeNHzTSg(TRSKdata[[2]],"TROITSK")
writeNHzTSg(SCHLdata[[2]],"SCHOOL1234")
writeNHzTSg(SHERdata[[2]],"SCHERBINKA")

writeTairRhTSg(RUDNdata[[2]],"RUDN")
writeTairRhTSg(TIMdata[[2]],"Timiryazev")
writeTairRhTSg(BLTNdata[[2]],"BOLOTNAYA")
writeTairRhTSg(HORTdata[[2]],"GARDEN")
writeTairRhTSg(TRSKdata[[2]],"TROITSK")
writeTairRhTSg(SCHLdata[[2]],"SCHOOL1234")
writeTairRhTSg(SHERdata[[2]],"SCHERBINKA")


writeAngleDeviation(RUDNdata[[2]],"RUDN")
writeAngleDeviation(TIMdata[[2]],"Timiryazev")
writeAngleDeviation(BLTNdata[[2]],"BOLOTNAYA")
writeAngleDeviation(HORTdata[[2]],"GARDEN")
writeAngleDeviation(TRSKdata[[2]],"TROITSK")
writeAngleDeviation(SCHLdata[[2]],"SCHOOL1234")
writeAngleDeviation(SHERdata[[2]],"SCHERBINKA")



writeAngleDeviationTT(RUDNdata[[2]],"RUDN")
writeAngleDeviationTT(TIMdata[[2]],"Timiryazev")
writeAngleDeviationTT(BLTNdata[[2]],"BOLOTNAYA")
writeAngleDeviationTT(HORTdata[[2]],"GARDEN")
writeAngleDeviationTT(TRSKdata[[2]],"TROITSK")
writeAngleDeviationTT(SCHLdata[[2]],"SCHOOL1234")
writeAngleDeviationTT(SHERdata[[2]],"SCHERBINKA")


writeZ2TT(RUDNdata[[2]],"RUDN", meteo_data)
writeZ2TT(TIMdata[[2]],"Timiryazev", meteo_data)
writeZ2TT(BLTNdata[[2]],"BOLOTNAYA", meteo_data)
writeZ2TT(HORTdata[[2]],"GARDEN", meteo_data)
writeZ2TT(TRSKdata[[2]],"TROITSK", meteo_data)
writeZ2TT(SCHLdata[[2]],"SCHOOL1234", meteo_data)
writeZ2TT(SHERdata[[2]],"SCHERBINKA", meteo_data)


sData  = RUDNdata[[2]]%>% filter(doy >219 & doy<226 ) %>%
  filter(id %in% c("218A0173","218A0155","218A0146","218A0230","218A0221",
                   "218A0218","218A0140","218A0139","218A0115","218A0110",
                   "218A0108","218A0106","218A0100","218A0085","218A0064"))







writeZ2TTh(sData,"RUDN", meteo_data)



writeZ2TTh(TIMdata[[2]],"Timiryazev", meteo_data)
writeZ2TTh(BLTNdata[[2]],"BOLOTNAYA", meteo_data)
writeZ2TTh(HORTdata[[2]],"GARDEN", meteo_data)
writeZ2TTh(TRSKdata[[2]],"TROITSK", meteo_data)
writeZ2TTh(SCHLdata[[2]],"SCHOOL1234", meteo_data)
writeZ2TTh(SHERdata[[2]],"SCHERBINKA", meteo_data)

writeZ2(RUDNdata[[2]],"RUDN", meteo_data)
writeZ2(TIMdata[[2]],"Timiryazev", meteo_data)
writeZ2(BLTNdata[[2]],"BOLOTNAYA", meteo_data)
writeZ2(HORTdata[[2]],"GARDEN", meteo_data)
writeZ2(TRSKdata[[2]],"TROITSK", meteo_data)
writeZ2(SCHLdata[[2]],"SCHOOL1234", meteo_data)
writeZ2(SHERdata[[2]],"SCHERBINKA", meteo_data)






#  
#  Таблицы среднихз макс мин значений потока, ндви, для каждого вида усредненный
#  
#  !!!!Посчитать возраста по феногруппам!!!!!! Добавить колонку в первую главу
#  
#  NDVI глава 2 добавить таблицу
#  
#  Расписать кто высокий кто низкий
#  
#  Ответить на TT 259, 263, 279
#  
#  Имена участков
#  
#  Показать что NDVI работает для ВТА и валить на то, что 
#  
#  Внутри сайтовое сравнение антроп нагрузке
#  
#  DONE Ольгу пнуть по ее пунктам
#  
#  Добавить в финальные таблицы наши экстремальные значения 




AllData%>%group_by(Site)%>%summarise(age  = mean(age_group))





AllData2 =AllData
AllData2 = AllData2 %>% as.data.frame()
for (i in 1:ncol(AllData2)){
  AllData2[ AllData2[,i] %>% is.infinite(),i] = NA  
}
AllData2$month = month(AllData2$time)
SumaryAllmData = AllData2 %>% group_by(doy,id) %>% mutate(psi_d = mean(psi, na.rm = T),
                                                        phi_d = mean(phi, na.rm = T), 
                                                        theta_d = mean(theta, na.rm = T))%>%
  ungroup() %>% group_by(doy, id) %>% mutate(
    dtheta  = (theta- theta_d),
    dphi  = (phi- phi_d),
    dpsi  = (psi- psi_d)) %>% ungroup() %>%
  mutate(g2 = gx2+gy2+gz2,
         mHz = max(Hz, na.rm = T))%>%
  mutate(Hzmoist = (mHz-Hz)/(mHz+Hz)*50) %>%
  group_by(id,Site,Species,month, ) %>% 
  summarise(
    DBH = mean(DBH, na.rm = T),
    dthetamav = mean(dtheta, na.rm = T),
    dphimav = mean(dphi, na.rm = T),
    dpsimav = mean(dpsi, na.rm = T),
    g2mav = mean(g2, na.rm = T),
    tairm = mean(tair, na.rm = T),
    rhm = mean(rh, na.rm = T),
    NDVImav = mean(NDVI, na.rm = T),
    PRImav = mean(PRI, na.rm = T),
    PSNDmav = mean(PSND, na.rm=T),
    CRI2mav = mean(CRI2, na.rm=T),
    Hzmositmav = mean(Hzmoist, na.rm = T),
    Fluxmav = mean(Flux, na.rm = T),
    tmav = mean(tair, na.rm = T),
    VPDmav = mean(VPD, na.rm = T),
    dthetamsd = sd(dtheta, na.rm = T),
    dphimsd = sd(dphi, na.rm = T),
    dpsimsd = sd(dpsi, na.rm = T),
    g2msd = sd(g2, na.rm = T),
    tairsd = sd(tair, na.rm = T),
    rhsd = sd(rh, na.rm = T),
    NDVImsd = sd(NDVI, na.rm = T),
    PRImsd = sd(PRI, na.rm = T),
    PSNDmsd = sd(PSND, na.rm=T),
    CRI2msd = sd(CRI2, na.rm=T),
    Hzmositmsd = sd(Hzmoist, na.rm = T),
    Fluxmsd = sd(Flux, na.rm = T),
    tmsd = sd(tair, na.rm = T),
    VPDmsd = sd(VPD, na.rm = T),
    dthetamq10 = quantile(dtheta,0.1, na.rm = T),
    dphimq10 = quantile(dphi,0.1, na.rm = T),
    dpsimq10 = quantile(dpsi,0.1, na.rm = T),
    g2mq10 = quantile(g2,0.1, na.rm = T),
    tairq10 = quantile(tair,0.1, na.rm = T),
    rhq10 = quantile(rh,0.1, na.rm = T),
    NDVImq10 = quantile(NDVI,0.1, na.rm = T),
     PRImsq10 = quantile(PRI,0.1, na.rm = T),
     PSNDmq10 = quantile(PSND,0.1, na.rm=T),
     CRI2mq10 = quantile(CRI2,0.1, na.rm=T),
     Hzmositmq10 = quantile(Hzmoist,0.1, na.rm = T),
     Fluxmq10 = quantile(Flux,0.1, na.rm = T),
     VPDmq10 = quantile(VPD,0.1, na.rm = T),
     tmq10 = quantile(tair,0.1, na.rm = T),
    dthetamq90 = quantile(dtheta,0.9, na.rm = T),
    dphimq90 = quantile(dphi,0.9, na.rm = T),
    dpsimq90 = quantile(dpsi,0.9, na.rm = T),
    tairq90 = quantile(tair,0.9, na.rm = T),
    rhq90 = quantile(rh,0.9, na.rm = T),
    g2mq90 = quantile(g2,0.9, na.rm = T),
     NDVImq90 = quantile(NDVI,0.9, na.rm = T),
     PRImq90 = quantile(PRI,0.9, na.rm = T),
     PSNDmq90 = quantile(PSND,0.9, na.rm=T),
     CRI2mq90 = quantile(CRI2,0.9, na.rm=T),
     Hzmositmq90 = quantile(Hzmoist,0.9, na.rm = T),
     Fluxmq90 = quantile(Flux,0.9, na.rm = T),
     tmq90 = quantile(tair,0.9, na.rm = T),
     VPDmq90 = quantile(VPD,0.9, na.rm = T),
    dthetammd = quantile(dtheta,0.5, na.rm = T),
    dphimmd = quantile(dphi,0.5, na.rm = T),
    dpsimmd = quantile(dpsi,0.5, na.rm = T),
    tairmd = quantile(tair,0.5, na.rm = T),
    rhmd = quantile(rh,0.5, na.rm = T),
    g2mmd = quantile(g2,0.5, na.rm = T),
     NDVImmd = quantile(NDVI,0.5, na.rm = T),
     PRImmd = quantile(PRI,0.5, na.rm = T),
     PSNDmmd = quantile(PSND,0.5, na.rm=T),
     CRI2mmd = quantile(CRI2,0.5, na.rm=T),
     Hzmositmmd = quantile(Hzmoist,0.1, na.rm = T),
     Fluxmmd = quantile(Flux,0.5, na.rm = T),
     VPDmmd = quantile(VPD,0.5, na.rm = T),
     tmsum = sum(tair/length(Flux)*720, na.rm = T),
     VPDmsum = sum(VPD/length(Flux)*720, na.rm = T),
     Fluxmsum = sum(Flux/length(Flux)*720, na.rm = T),
     #growth = mean(growth, na.rm=T)
)



SumaryAllyData = AllData2 %>% group_by(doy,id) %>% mutate(psi_d = mean(psi, na.rm = T),
                                                         phi_d = mean(phi, na.rm = T), 
                                                         theta_d = mean(theta, na.rm = T))%>%
  ungroup() %>% group_by(doy, id) %>% mutate(
    dtheta  = (theta- theta_d),
    dphi  = (phi- phi_d),
    dpsi  = (psi- psi_d)) %>% ungroup() %>%
  mutate(g2 = gx2+gy2+gz2,
         mHz = max(Hz, na.rm = T))%>%
  mutate(Hzmoist = (mHz-Hz)/(mHz+Hz)*50) %>%
  group_by(id,Site,Species) %>% 
  summarise(
    DBH = mean(DBH, na.rm = T),
    dthetamav = mean(dtheta, na.rm = T),
    dphimav = mean(dphi, na.rm = T),
    dpsimav = mean(dpsi, na.rm = T),
    g2mav = mean(g2, na.rm = T),
    tairm = mean(tair, na.rm = T),
    rhm = mean(rh, na.rm = T),
    NDVImav = mean(NDVI, na.rm = T),
    PRImav = mean(PRI, na.rm = T),
    PSNDmav = mean(PSND, na.rm=T),
    CRI2mav = mean(CRI2, na.rm=T),
    Hzmositmav = mean(Hzmoist, na.rm = T),
    Fluxmav = mean(Flux, na.rm = T),
    tmav = mean(tair, na.rm = T),
    VPDmav = mean(VPD, na.rm = T),
    dthetamsd = sd(dtheta, na.rm = T),
    dphimsd = sd(dphi, na.rm = T),
    dpsimsd = sd(dpsi, na.rm = T),
    g2msd = sd(g2, na.rm = T),
    tairsd = sd(tair, na.rm = T),
    rhsd = sd(rh, na.rm = T),
    NDVImsd = sd(NDVI, na.rm = T),
    PRImsd = sd(PRI, na.rm = T),
    PSNDmsd = sd(PSND, na.rm=T),
    CRI2msd = sd(CRI2, na.rm=T),
    Hzmositmsd = sd(Hzmoist, na.rm = T),
    Fluxmsd = sd(Flux, na.rm = T),
    tmsd = sd(tair, na.rm = T),
    VPDmsd = sd(VPD, na.rm = T),
    dthetamq10 = quantile(dtheta,0.1, na.rm = T),
    dphimq10 = quantile(dphi,0.1, na.rm = T),
    dpsimq10 = quantile(dpsi,0.1, na.rm = T),
    g2mq10 = quantile(g2,0.1, na.rm = T),
    tairq10 = quantile(tair,0.1, na.rm = T),
    rhq10 = quantile(rh,0.1, na.rm = T),
    NDVImq10 = quantile(NDVI,0.1, na.rm = T),
    PRImsq10 = quantile(PRI,0.1, na.rm = T),
    PSNDmq10 = quantile(PSND,0.1, na.rm=T),
    CRI2mq10 = quantile(CRI2,0.1, na.rm=T),
    Hzmositmq10 = quantile(Hzmoist,0.1, na.rm = T),
    Fluxmq10 = quantile(Flux,0.1, na.rm = T),
    VPDmq10 = quantile(VPD,0.1, na.rm = T),
    tmq10 = quantile(tair,0.1, na.rm = T),
    dthetamq90 = quantile(dtheta,0.9, na.rm = T),
    dphimq90 = quantile(dphi,0.9, na.rm = T),
    dpsimq90 = quantile(dpsi,0.9, na.rm = T),
    tairq90 = quantile(tair,0.9, na.rm = T),
    rhq90 = quantile(rh,0.9, na.rm = T),
    g2mq90 = quantile(g2,0.9, na.rm = T),
    NDVImq90 = quantile(NDVI,0.9, na.rm = T),
    PRImq90 = quantile(PRI,0.9, na.rm = T),
    PSNDmq90 = quantile(PSND,0.9, na.rm=T),
    CRI2mq90 = quantile(CRI2,0.9, na.rm=T),
    Hzmositmq90 = quantile(Hzmoist,0.9, na.rm = T),
    Fluxmq90 = quantile(Flux,0.9, na.rm = T),
    tmq90 = quantile(tair,0.9, na.rm = T),
    VPDmq90 = quantile(VPD,0.9, na.rm = T),
    dthetammd = quantile(dtheta,0.5, na.rm = T),
    dphimmd = quantile(dphi,0.5, na.rm = T),
    dpsimmd = quantile(dpsi,0.5, na.rm = T),
    tairmd = quantile(tair,0.5, na.rm = T),
    rhmd = quantile(rh,0.5, na.rm = T),
    g2mmd = quantile(g2,0.5, na.rm = T),
    NDVImmd = quantile(NDVI,0.5, na.rm = T),
    PRImmd = quantile(PRI,0.5, na.rm = T),
    PSNDmmd = quantile(PSND,0.5, na.rm=T),
    CRI2mmd = quantile(CRI2,0.5, na.rm=T),
    Hzmositmmd = quantile(Hzmoist,0.1, na.rm = T),
    Fluxmmd = quantile(Flux,0.5, na.rm = T),
    VPDmmd = quantile(VPD,0.5, na.rm = T),
    tmsum = sum(tair/length(Flux)*720, na.rm = T),
    VPDmsum = sum(VPD/length(Flux)*720, na.rm = T),
    Fluxmsum = sum(Flux/length(Flux)*720, na.rm = T),
    #growth = max(growth, na.rm=T)
  )

SumaryAllyData$month = 0


SummmaryData = dplyr::union(SumaryAllmData,SumaryAllyData)

SummmaryData = SummmaryData %>% arrange(id)


write.csv(SummmaryData, file="SummaryAllTTDatawGrowth.csv")

SumaryGrowthmDataSite = SummmaryData  %>% group_by(Species,Site,month) %>% summarise(
  mean = mean(growth, na.rm=T),
  sd = sd(growth, na.rm=T),
  max = quantile(growth,0.9, na.rm = T),
  median = quantile(growth,0.5, na.rm = T),
  min = quantile(growth,0.1, na.rm = T),
)

SumaryGrowthmData = SummmaryData  %>% group_by(Species,month) %>% summarise(
  mean = mean(growth, na.rm=T),
  sd = sd(growth, na.rm=T),
  max = quantile(growth,0.9, na.rm = T),
  median = quantile(growth,0.5, na.rm = T),
  min = quantile(growth,0.1, na.rm = T),
)




SumaryTairmDataSite = SummmaryData  %>% group_by(Species,Site,month) %>% summarise(
  mean = mean(tair, na.rm=T),
  sd = sd(tair, na.rm=T),
  max = quantile(tair,0.9, na.rm = T),
  median = quantile(tair,0.5, na.rm = T),
  min = quantile(tair,0.1, na.rm = T),
)

SumaryRhmData = SummmaryData  %>% group_by(Species,Site,month) %>% summarise(
  mean = mean(rh, na.rm=T),
  sd = sd(rh, na.rm=T),
  max = quantile(rh,0.9, na.rm = T),
  median = quantile(rh,0.5, na.rm = T),
  min = quantile(rh,0.1, na.rm = T),
)



write.csv(SumaryGrowthmDataSite, file="SumaryGrowthmDataSite.csv")
write.csv(SumaryGrowthmData, file="SumaryGrowthmData.csv")

SumaryGrowthmDataSite %>% as.data.frame()


TRSKdata[[2]]$id%>%unique()

########################## NDVI verification ##################################

#ALways better to do on your own
library(sf)
library(raster)
library(rgdal)
library(rgeos)
library(RColorBrewer)

TTcanopies = read_sf("TT_canopies.geojson")
TTcanopies = TTcanopies[-7:-1,]

RUDN <- stack("Y:\\YandexDisk\\NDVI\\SATELITE_DATA\\011169772030_01\\011169772030_01_P001_MUL\\19JUN04090505-M2AS-011169772030_01_P001.TIF")
RUDN <- brick(RUDN)

TIM <- stack("Y:\\YandexDisk\\NDVI\\SATELITE_DATA\\011169772050_01\\011169772050_01_P001_MUL\\19JUN04090502-M2AS-011169772050_01_P001.TIF")
TIM <- brick(TIM)


refl_NIR = function(nir){
  Lnir = nir*0.982*0.117971/1.004-3.752
  JD = 2458638.87853
  D = JD - 2451545.0
  g  = 357.529 + 0.98560028 * D
  d  = 1.00014 - 0.01671 * cos(g/180*pi) - 0.00014 * cos(2*g/180*pi)
  SunEl = 56.5
  phi = 90 - SunEl
  Enir = 1071.98
  Rnir = Lnir * d^2 * pi / (Enir*cos(phi/180*pi))
  return(Rnir)
} 

refl_RED = function(red){
  
  Lred = red*0.945*1.02/5.85-1.350
  JD = 2458638.87853
  D = JD - 2451545.0
  g  = 357.529 + 0.98560028 * D
  d  = 1.00014 - 0.01671 * cos(g/180*pi) - 0.00014 * cos(2*g/180*pi)
  SunEl = 56.5
  phi = 90 - SunEl
  Ered = 1555.11
  Rred = Lred * d^2 * pi / (Ered*cos(phi/180*pi))
  return(Rred)
} 

refl_NDVI = function(raster,nir_band,red_band){
  red = refl_RED(raster[[red_band]])
  nir = refl_NIR(raster[[nir_band]])
  ndvi = (nir-red)/(nir+red)
  return(ndvi)
}

rudn_ndvi = refl_NDVI(RUDN,4,3)  
tim_ndvi = refl_NDVI(TIM,4,3) 
timrudn_ndvi = raster::merge(rudn_ndvi,tim_ndvi)

writeRaster(rudn_ndvi, filename=file.path(getwd(), "rudn_ndvi.tif"), format="GTiff", overwrite=TRUE)
writeRaster(tim_ndvi, filename=file.path(getwd(), "tim_ndvi.tif"), format="GTiff", overwrite=TRUE)

q85 = function(x){
  return(quantile(x,0.85))
}

TTndvi = TTcanopies %>% mutate(
  NDVIMean = raster::extract(timrudn_ndvi, TTcanopies, fun = mean, na.rm = TRUE),
  NDVIMax = raster::extract(timrudn_ndvi, TTcanopies, fun = max, na.rm = TRUE),
  NDVIMin = raster::extract(timrudn_ndvi, TTcanopies, fun = min, na.rm = TRUE),
) %>% as.data.frame() %>% dplyr::select(-geometry)




NDVI_TT_score = AllData %>% filter(doy == 155, id %in% TTndvi$id) %>% left_join(TTndvi , by="id")%>%
                               filter(!is.na(NDVI))%>%
                               mutate(av_score = abs(NDVI - NDVIMean), 
                                      min_score = abs(NDVI - NDVIMin),
                                      max_score=abs(NDVI-NDVIMax),
                                      hour_score1=abs(hour-12),
                                      hour_score2=abs(hour-11),
                                      hour_score3=abs(hour-6))%>%
                               group_by(id)%>%summarise( hour_av = hour[which.min(av_score)],
                                                         hour_min = hour[which.min(min_score)],
                                                         hour_max = hour[which.min(max_score)], 
                                                         NDVI_tt_av = NDVI[which.min(av_score)],
                                                         NDVI_tt_min = NDVI[which.min(min_score)],
                                                         NDVI_tt_max = NDVI[which.min(max_score)],
                                                         NDVI_time = NDVI[which.min(hour_score1)],
                                                         NDVI_time2 = NDVI[which.min(hour_score2)],
                                                         NDVI_time3 = NDVI[which.min(hour_score3)],
                                                         NDVI_av = NDVIMean[which.min(av_score)],
                                                         NDVI_min = NDVIMin[which.min(min_score)],
                                                         NDVI_max = NDVIMax[which.min(max_score)],
                                                         NDVIMean = mean(NDVIMean))

NDVI_TT_score %>% as.data.frame()


NDVI_TT = AllData %>% filter(doy == 155, id %in% TTndvi$id%>%unique) %>%filter(!is.na(NDVI))%>%group_by(id)%>%
  summarise(mean = mean(NDVI, na.rm=T), 
            min = min(NDVI, na.rm = T),
            max = max(NDVI, na.rm = T))
         

TT = left_join(NDVI_TT,TTndvi, by="id")%>%as.data.frame()
plot(x=TT$max,y = TT$NDVIMax)

ggplot(data = NDVI_TT_score)+
  geom_point(aes(x=NDVI_tt_av, y=NDVI_av),color=1)+
  geom_point(aes(x=NDVI_tt_min, y=NDVI_min),color=2)+
  geom_point(aes(x=NDVI_tt_max, y=NDVI_max),color=3)


ggplot(data = NDVI_TT_score)+
  geom_smooth(aes(x=NDVI_tt_min, y=NDVI_min), method = lm, color=3)+
  geom_point(aes(x=NDVI_tt_min, y=NDVI_min),color=3)+
  xlab("NDVI по данными TreeTalker")+
  ylab("NDVI по данными спутника WorldView 3")+
  theme_bw()+
  theme(axis.text=element_text(size=14),
        axis.title=element_text(size=16,face="bold"))
  




  mean_mod = lm(data = NDVI_TT_score, NDVI_tt_av~NDVI_av) %>% summary
  min_mod  = lm(data = NDVI_TT_score, NDVI_tt_min~NDVI_min)  %>% summary
  max_mod  = lm(data = NDVI_TT_score, NDVI_tt_max~NDVI_max) %>% summary
  mod  = lm(data = TT%>%filter (max!=1), max~NDVIMax) %>% summary
  
 
  


########################## VTA PCA and CROCOR ##################################

#library(devtools)
#install_github("vqv/ggbiplot")

library(ggbiplot)
library(Hmisc)
library(corrplot)
library(stringr)


AllTTDataWgrowth <- read_csv("AllTTDataWgrowth.csv", 
                             col_types = cols(X1 = col_skip(), 
                             datetime = col_datetime(format = "%Y-%m-%d %H:%M:%S"), 
                            serv_datetime = col_datetime(format = "%Y-%m-%d %H:%M:%S"),
                            time = col_datetime(format = "%Y-%m-%d %H:%M:%S")))

names(SummaryWithVTA)
SummaryWithVTA = left_join(AllTTDataWgrowth, VTA, by="id")

SummWithVTA = SummaryWithVTA%>%group_by(id,leaves_quality,crown_density,crown_codominance,wounds,
            cracks,cavities,fungi,trunk_inclination,curvature,trunk_codominance,pruning,trunk_rot,
            trunk_cavities,outgrowthing,insects,epicormic_shoots,superficial_roots,raised_roots,winding_roots,
            roots_damages,asphalt, Species,Site,)%>%summarise(DBH=mean(DBH))
write.csv(SummWithVTA,file="SummWithVTA.csv")

VTA = read_delim("VTA.csv", ";", escape_double = FALSE,trim_ws = TRUE)
VTA$id = paste("218A",VTA$id, sep="")
VTA = VTA %>%mutate(score = rowMeans(.[2:23], na.rm = T))
VTAscore =VTA %>% as.data.frame %>% dplyr::select(id, score)
library(readxl)
TT_MOS_DESC <- read_excel("TT_MOS_DESC.xlsx", col_types = c("text", "text", "numeric", 
                          "numeric", "numeric", "text", "text", "numeric", "skip", "skip", "numeric"))
TT_DESC = left_join(TT_MOS_DESC,VTAscore, by = "id")
write.csv(TT_DESC, file="all_TT_desc.csv")


VTA_PCA = left_join(SumaryAllmData, VTA, by="id")
VTA_PCA.raw = VTA_PCA[,4:91]%>%select(-g2mmd)%>%select(-g2mq10)
VTA_PCA.raw$growth[is.infinite(VTA_PCA.raw$growth)] = 0
VTA_PCA.raw = na.exclude(VTA_PCA.raw) 

VTA.pca = prcomp(VTA_PCA.raw, center = TRUE, scale = TRUE)

ggbiplot(VTA.pca,groups = VTA.pca$month, obs.scale = 1, var.scale = 1, ellipse=TRUE, circle = TRUE) +
  scale_color_discrete(name = '') +theme_bw()+xlim(-5,5)

ggscreeplot(VTA.pca, type = c("pev", "cev"))


################################# CORELLOGRAMS #################################

VTA.cor = cor(VTA_PCA.raw )

col<- colorRampPalette(c("blue", "white", "red"))(20)
heatmap(x = VTA.cor, col = col, symm = TRUE)

#ttleaf.sign.filtered = ttleaf.pca.filtered[,c(22:25,15:18,2,7,12)]
res2 <- rcorr(as.matrix(VTA_PCA.raw))

corrplot(res2$r, type="full", order="FPC", 
         p.mat = res2$P, sig.level = 0.01, insig = "blank")



 




out_of_two_sigma(data$Flux)

var_n =  na.exclude(data$Flux) > mean(na.exclude(data$Flux), na.rm=T) + 2*sd(as.vector(data$Flux), na.rm = T) | 
        na.exclude(data$Flux) < mean(na.exclude(data$Flux), na.rm=T) - 2*sd(na.exclude(data$Flux), na.rm=T)

class(data$Flux)
AllData$pulses



SummaryTableNDVI = AllData %>% group_by(Site,Species,doy, id, ) %>% filter(NDVI > 0 & NDVI < 0.97) %>%  
  summarise( mNDVI = quantile(NDVI,0.9, na.rm=T), sNDVI = sd(NDVI, na.rm=T), Flux = quantile(Flux,0.9, na.rm=T), VTAscore = mean(VTAscore)) %>% 
   group_by(Site,Species) %>% 
  summarise( NDVI = mean(mNDVI, na.rm=T), sNDVI = sd(mNDVI, na.rm=T),mxNDVI = max(mNDVI, na.rm=T) ,mnNDVI = min(mNDVI, na.rm=T))

SummaryTableNDVI%>%as.data.frame()

SummaryTableVTA = SummaryTableNDVI %>% group_by(VTAscr,Species)%>%
  summarise(mxNDVI = mean(mxNDVI),mnNDVI = mean(mnNDVI),mNDVI = mean(mNDVI), mFlux=mean(mFlux))%>%
  arrange(Species)%>%as.data.frame()

SummaryTablePRI = AllData %>% group_by(Site,Species,doy, id) %>% filter(PRI > 0 & PRI < 0.97) %>%
  summarise( mPRI = quantile(PRI,0.2, na.rm=T),VTAscore = mean(VTAscore) ) %>% group_by(Site,Species, id) %>%
  summarise( mPRI = quantile(mPRI,0.2, na.rm=T),VTAscore = mean(VTAscore) )

models = SummaryTableNDVI %>% group_by(Species) %>% mutate(TTscr = log(mFlux/mNDVI))%>% na.exclude %>% 
  filter(!is.infinite(mFlux)) %>% filter(!out_of_two_sigma(TTscr)) %>%  summarise(R2 = cor(sNDVI,VTAscr)^2)



SummaryTableOptimalCritical = AllData %>% group_by(Site,Species,doy, id, age_group) %>% 
  filter(NDVI > 0 & NDVI < 0.97) %>% filter(month <9)%>% filter(!is.infinite(Flux))%>%
  summarise( optNDVI = quantile(NDVI,0.9, na.rm=T), critNDVI = quantile(NDVI,0.2, na.rm=T),
             optFlux = quantile(Flux,0.9, na.rm=T), critFlux = quantile(Flux,0.2, na.rm=T))%>%
  group_by(Species, age_group) %>% 
    summarise( optNDVI = mean(optNDVI, na.rm=T), critNDVI = mean(critNDVI, na.rm=T),
               optFlux = mean(optFlux, na.rm=T), critFlux = mean(critFlux,0.2, na.rm=T))

  SummaryTableOptimalCritical %>%as.data.frame()
  
  
  
SummaryTableANOVA = AllData %>% group_by(Site,Species,doy, id, age_group, age_group_index) %>% 
    filter(NDVI > 0 & NDVI < 0.97) %>% filter(month <9)%>% filter(!is.infinite(Flux))%>%
    summarise( optNDVI = quantile(NDVI,0.9, na.rm=T), critNDVI = quantile(NDVI,0.2, na.rm=T),
               optFlux = quantile(Flux,0.9, na.rm=T), critFlux = quantile(Flux,0.2, na.rm=T))


SummaryTableANOVA = AllData %>% group_by(Site,Species,doy, id, age_group, age_group_index, VTAscore) %>% 
  filter(NDVI > 0 & NDVI < 0.97) %>% filter(month <9)%>% filter(!is.infinite(Flux))%>%
  summarise( optNDVI = quantile(NDVI,0.8, na.rm=T), critNDVI = quantile(NDVI,0.2, na.rm=T),
             optFlux = quantile(Flux,0.6, na.rm=T), critFlux = quantile(Flux,0.2, na.rm=T))
  
modFLux = lm(data = SummaryTableANOVA, optFlux~Species+VTAscore)
anova(lm(data = SummaryTableANOVA, optFlux~Species+VTAscore))
anova(lm(data = SummaryTableANOVA, optNDVI~Species+VTAscore))
anova(lm(data = SummaryTableANOVA, critFlux~Species+VTAscore))
anova(lm(data = SummaryTableANOVA, critNDVI~Species+VTAscore))

TablesGraph = SummaryTableANOVA %>% group_by(Species)%>%do(graph = 
ggplot(data = .)+
  geom_boxplot(aes(y=optFlux, x = as.factor(age_group), ymax = 20))+
  ylim(c(0,20))+
  scale_color_lancet()+
  theme_bw()
  
)

TablesGraph[5,2][[1]]


SummaryTableANOVAm = AllData %>% filter(Species %in% c("Acer platanoides","Betula pendula","Larix sibirica", "Pinus sylvestris",
                "Picea abies","Quercus robur","Tilia cordata")) %>% group_by(Site,Species,doy, id, age_group, age_group_index) %>% 
  filter(NDVI > 0 & NDVI < 0.97) %>% filter(month <9)%>% filter(!is.infinite(Flux))%>%
  summarise( optNDVI = quantile(NDVI,0.9, na.rm=T), critNDVI = quantile(NDVI,0.2, na.rm=T),
             optFlux = quantile(Flux,0.9, na.rm=T), critFlux = quantile(Flux,0.2, na.rm=T))%>%
group_by(Species,age_group,age_group_index)%>%na.exclude()%>%
  summarise(Fluxm = mean(optFlux, na.rm=T),  Flux_er = (CI(optFlux)[1]-CI(optFlux)[3])/2, NDVIm = mean(optNDVI, na.rm=T), 
            NDVIer = (CI(optNDVI)[1]-CI(optNDVI)[3])/2,m = length(optFlux) )


ggplot(data = SummaryTableANOVAm%>%filter(Species %in% c("Acer platanoides","Betula Pendula","Larix sibirica",
                                                        "Pinus sylvestris","Picea abies","Quercus robur","Tilia cordata")))+
  geom_line(aes(y=Fluxm, x = age_group_index, group = Species, color = Species),position = position_dodge(width = 0.1), size=1)+
  geom_errorbar(aes(ymin=Fluxm-Flux_er, ymax=Fluxm+Flux_er ,
                    x=age_group_index, group=Species, color=Species),position = position_dodge(width = 0.1), size=1, width = .2) +
  
  ylim(c(0,20))+
  scale_color_lancet()+
  theme_bw()



SummaryTableANOVAm = AllData %>% filter(Species %in% c("Acer platanoides","Betula pendula",
        "Larix sibirica", "Pinus sylvestris","Picea abies","Quercus robur","Tilia cordata")) %>% 
  group_by(Site,Species,doy, id, VTAscore) %>% 
  filter(NDVI > 0 & NDVI < 0.97) %>% filter(month <9)%>% filter(!is.infinite(Flux))%>%
  summarise( optNDVI = quantile(NDVI,0.9, na.rm=T), critNDVI = quantile(NDVI,0.2, na.rm=T),
             optFlux = quantile(Flux,0.9, na.rm=T), critFlux = quantile(Flux,0.2, na.rm=T))%>%
  group_by(Species,VTAscore)%>%na.exclude()%>%
  summarise(Fluxm = mean(optFlux, na.rm=T),  Flux_er = (CI(optFlux)[1]-CI(optFlux)[3])/2, NDVIm = mean(optNDVI, na.rm=T), 
            NDVIer = (CI(optNDVI)[1]-CI(optNDVI)[3])/2,m = length(optFlux) )


ggplot(data = SummaryTableANOVAm%>%filter(Species %in% c("Acer platanoides","Betula pendula",
                                                         "Larix sibirica", "Pinus sylvestris","Picea abies","Quercus robur","Tilia cordata")))+
  geom_line(aes(y=Fluxm, x = VTAscore, group = Species, color = Species),position = position_dodge(width = 0.1), size=1)+
  geom_errorbar(aes(ymin=Fluxm-Flux_er, ymax=Fluxm+Flux_er ,
                    x=VTAscore, group=Species, color=Species),position = position_dodge(width = 0.1), size=1, width = .2) +
  
  ylim(c(0,5))+
  ylab("Скорость сокотечения л/ч")+
  xlab("Категория состояния дерева")+
  labs(color = "Виды")+
  scale_color_lancet()+
  theme_bw()


ggplot(data = SummaryTableANOVAm%>%filter(Species %in% c("Acer platanoides","Betula pendula",
                                                         "Larix sibirica", "Pinus sylvestris","Picea abies","Quercus robur","Tilia cordata")))+
  geom_line(aes(y=NDVIm, x = VTAscore, group = Species, color = Species),position = position_dodge(width = 0.1), size=1)+
  geom_errorbar(aes(ymin=NDVIm-NDVIer, ymax=NDVIm+NDVIer ,
                    x=VTAscore, group=Species, color=Species),position = position_dodge(width = 0.1), size=1, width = .2) +
  
  ylim(c(0,1))+
  ylab("NDVI")+
  labs(color = "Виды")+
  xlab("Категория состояния дерева")+
  scale_color_lancet()+
  theme_bw()








 SummaryTableANOVA$optFlux %>% max(na.rm = T)

SummaryVTAvsNDVI = left_join(SummaryTableNDVI, models, by="Species") %>% 
                  filter(Species %in% c("Acer platanoides", "Betula pendula", "Fraxinus","Pinus sylvestris", "Quercus robur", "Tilia cordata"))%>%
  ungroup %>% select(id,Species, mNDVI,mFlux, VTAscr, R2) %>% mutate(TTscr = mFlux/ mNDVI)
                  
SummaryVTAvsNDVI %>%arrange(Species)%>% as.data.frame()

 summary(models[10,2][[1]][[1]])$r.squared
models[17,2][[1]][[1]]%>%summary


ggplot(data = SummaryTableNDVI )+geom_point(aes(x=VTAscr,y=mxNDVI - mnNDVI, color =age_group))
ggplot(data = SummaryTablePRI)+geom_point(aes(x=VTAscore,y=log(mPRI)))
PRImod = lm(data = SummaryTablePRI, VTAscore~log(mPRI))
summary(PRImod)
####################### TABLES GENERATOR ################################33


library(summarytools)

SummaryTableFlux = AllData%>%group_by(Site, Species, doy, id) %>% mutate(update = length(id))%>%
  summarise(sFlux = sum(Flux, na.rm=T), readings = mean(update), diam = mean(diam, na.rm=T)) %>%
  mutate(suFlux = sFlux*readings/24) %>% filter(!is.na(suFlux)) %>% filter(!is.infinite(suFlux))%>%
  group_by(Species)%>%filter(!out_of_two_sigma(suFlux))%>%
  group_by(Site, Species, doy) %>% summarise(Flux = mean(suFlux, na.rm=T), d = mean(diam))

SummaryTableFlux %>% as.data.frame %>% group_by(Site, Species) %>% 
  summarise(mean = mean(Flux, na.rm=T), sd =sd(Flux, na.rm=T), max=max(Flux, na.rm=T), min=min(Flux, na.rm=T) ) %>%
  as.data.frame()
  

t = SummaryTableFlux %>% filter(Site == "RUDN", Species == "Acer platanoides ")%>% as.data.frame()

summary(t)

SummaryTableNDVI = AllData %>% group_by(Site,Species,doy, id) %>% filter(NDVI > 0 & NDVI < 0.97) %>%
  summarise( dNDVI = mean(NDVI, na.rm=T))  %>% filter(!out_of_two_sigma(dNDVI))
  
SummaryTableNDVI = SummaryTableNDVI %>% as.data.frame() %>% group_by(Site, Species) %>% 
  summarise(mean = mean(dNDVI, na.rm=T), sd =sd(dNDVI, na.rm=T), 
            max=max(dNDVI, na.rm=T), min=min(dNDVI, na.rm=T) ) %>%
  as.data.frame()

SummaryTableNDVIm = SummaryTableNDVI %>% as.data.frame() %>% group_by(Site, Species,month) %>% 
  summarise(mean = mean(dNDVI, na.rm=T), sd =sd(dNDVI, na.rm=T), 
            max=max(dNDVI, na.rm=T), min=min(dNDVI, na.rm=T) ) %>%
  as.data.frame()




SummaryTableHz = AllData%>%group_by(Site, Species, doy, id) %>%filter(!out_of_two_sigma(Hz)) %>% 
  summarise(hz = mean((46000-Hz)/(Hz+46000)*50, na.rm=T)) %>%na.omit() %>%
  filter(!is.infinite(hz))


SummaryTableHz = SummaryTableHz %>% as.data.frame() %>% 
  group_by(Site, Species) %>%   summarise(mean = mean(hz, na.rm=T), 
      sd =sd(hz, na.rm=T), max=max(hz, na.rm=T), min=min(hz, na.rm=T) ) %>%
  as.data.frame()


AllData$Hz%>%max


tt_imported = TRSKdata[[2]]
#tt_imported = tt_imported %>% mutate(same_time = time == datetime )
graph = ggplot(tt_imported )+
  geom_point( aes(x=time,y=volt, colour=imported%>%as.factor), size=.02)+
  facet_wrap(~id,  nrow = 6, strip.position = "bottom")
graph+theme_bw()


ttt = tt_imported %>% filter(id=="218A0204")

tt_acer1 = tt_imported %>% filter(Species == "Acer platanoides") %>% 
  filter(hour > 8 & hour < 17) %>% filter(b_O_600 > 5000)

tt_acer2 = BLTNdata[[2]] %>% filter(Species == "Acer platanoides") %>% 
  filter(hour > 8 & hour < 17) %>% filter(b_O_600 > 5000)

tt_acer3 = RUDNdata[[2]]  %>% filter(Species == "Acer platanoides ") %>% 
  filter(hour > 8 & hour < 17) %>% filter(b_O_600 > 5000)

tt_acer = rbind(tt_acer1,tt_acer2,tt_acer3)

+ex = tt_imported %>% filter(id == "218A0115")
#library(openxlsx)
write.xlsx(ex, file = "218A0115.xlsx")


data = RUDNdata[[2]]
data$Flux_f = two_sigma_weekly_flagging(data, Flux)
plots = data %>% group_by(Species) %>%
  do(
    plots = ggplot(data = .) + aes(x = time, y = Flux) +
      geom_smooth() + ggtitle(.$Species)
  )

plots$plots[1]


data2 = data %>% two_sigma_grouped_flagging(Flux, id, Species, "_fa")
data2$Flux_fa
ggplot(data = data%>%filter(Species == "Tilia cordata " ,!Flux_f, out_of_two_sigma(Flux)))+
  geom_point(aes(x=time, y=Flux))


plotbunch[3,2][[1]]


summ = data%>%group_by(Species, doy, id) %>% mutate(update = length(id))%>%
  summarise(sFlux = sum(Flux), readings = mean(update), diam = mean(diam, na.rm=T)) %>%
  mutate(suFlux = sFlux*readings/24)%>%
  group_by(Species, doy) %>% summarise(Flux = mean(suFlux, na.rm=T), d = mean(diam))

summ%>% as.data.frame()

ggplot(data = summ%>%filter(Species=="Acer platanoides "))+
  geom_smooth(aes(x=doy,y=Flux))+geom_point(aes(x=doy,y=Flux),size=.1)+ylim(0,100)+theme_bw()

####################### Sap flow velocity for Giovanna List ####################
tData  = TIMdata[[2]] 
l = list(c("218A0289","218A0298"),
         c("218A0143","218A0222","218A0218"),
         c("218A0061","218A0180"))



for(s in 1:length(l)){
  print(s)
  ttData = tData%>% filter(id %in% l[[s]]) %>% group_by(id,doy) %>% summarise(v = sum(u, na.rm=T)/24*length(u))
  graph = ggplot()
  for(i in 1:length( l[[s]] ) ){
    t = ttData %>% filter(id == l[[s]][i])
    graph = graph + geom_line(data = t, aes(x=doy,y=v, linetype=l[[s]][i]), color=i,size=.1)
  }
  graph = graph+theme_bw()+ylim(0,0.3)
  filename = c("Tillia.png","Quercus.png","Acer.png")[s]
  ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
  
}

for(s in 1:length(l)){
  print(s)
  ttData = tData%>% filter(id %in% l[[s]])%>%filter(!out_of_two_sigma(u)) 
  graph = ggplot()
  for(i in 1:length( l[[s]] ) ){
    t = ttData %>% filter(id == l[[s]][i])
    graph = graph + geom_line(data = t, aes(x=time,y=u), color=i,size=.1)
  }
  graph = graph+theme_bw()+ylim(0,0.05)
  filename = c("Tillia_h.png","Quercus_h.png","Acer_h.png")[s]
  ggsave(filename, graph,device = "png",width=5.83,height=4.13,units="in")
  
}

#################################FREE PROXIMITY################################
data = RUDNdata[[2]]
proximity_RUDN = read_delim("proximity_RUDN.csv",";", 
                            escape_double = FALSE, 
                            col_types = cols(X4 = col_skip(),
                                             X5 = col_skip(), X6 = col_skip(), 
                                             X7 = col_skip(), de = col_double()), 
                            trim_ws = TRUE)
data = left_join(data, proximity_RUDN, by="id")  

data$volt[which((round(data$dist13, digits=2) == data$ds & data$doy <160) | 
                  (round(data$dist13, digits =2) == data$de & data$doy >250 ))]
data$time[which((round(data$dist13, digits=2) == data$ds & data$doy <160) | 
                  (round(data$dist13, digits =2) == data$de & data$doy >250 ))]

pred = ggplot(data %>% filter(b_W_860 <10) %>% filter((volt > 3.99 & volt<4.05)))+
  geom_point(aes(x=doy,y=dist13 ), size=.1)+
  geom_smooth(aes(x=doy,y=dist13),method="loess" ,size=.1)+
  stat_smooth(aes(x=doy,y=dist13),method="loess" ,size=.1)+
  facet_wrap(~id)+ylim(0,50)+theme_bw()
ggplot_build(pred)$data[[2]]


#####LOOKING FOR PROBLEMS
sigma3_weekly_flaging  = function(data, var_name){
  #var_names = c("time",var_name)
  data = data %>% group_by(week) %>% mutate(s3flag = ) %>% 
}

RUDN = RUDNdata[[2]]


id2show = c("218A0100","218A0106","218A0109","218A0110","218A0155","218A0115",
            "218A0171","218A0060","218A0064","218A0141","218A0142","218A0114")
RUDN = RUDN %>%filter(doy>180)
RUDN = RUDN  %>% filter(id %in% id2show)
RUDN %>% group_by(id)%>% summarise(Sp = as.factor(Species)%>% levels)

RUDN = two_sigma_weekly_flagging(RUDN,u)
RUDN = two_sigma_weekly_flagging(RUDN,gz2)
RUDN = two_sigma_weekly_flagging(RUDN,psi)
RUDN = radiation_flagging(RUDN)
RUDN$NDVI[!RUDN$rad_flag]=NA
RUDN = RUDN %>% group_by(doy,id) %>% mutate(psi_d = mean(psi, na.rm = T),
                                            phi_d = mean(phi, na.rm = T), 
                                            theta_d = mean(theta, na.rm = T),
                                            ) %>% ungroup()


RUDN = RUDN %>% group_by(id) %>% mutate(mxt=max(theta_d-theta),
                                        mnt=min(theta_d-theta))


graph = ggplot(RUDN%>%filter(!u_f))+
  geom_step( aes(x=time,y=VPD/25), color=alpha(4,0.5), size=.02, )+
  geom_line( aes(x=time,y=u), size=.02)+
  geom_smooth( aes(x=time,y=NDVI/8), color=3, size=.02, span=1)+
  #geom_point( aes(x=time,y=NDVI/8), color=3, size=.02)+
  scale_y_continuous(name = expression(Sap~flow~density~" "~l~h^{-1}~m^{-2}),
                     sec.axis = sec_axis(~.*25, name = "VPD, kPa", labels = function(b) { round(b * 1, 2)}),
                     limits = c(0,0.15))+
  facet_wrap( vars(Species,id),  nrow = 4, strip.position = "bottom",labeller = label_bquote(.(Species) - .(id)))
graph+theme_bw()


graph = ggplot(RUDN)+
  facet_wrap( vars(Species,id),  nrow = 4, strip.position = "bottom",labeller = label_bquote(.(Species) - .(id)))+
  geom_line(aes(x=time,y=theta_d-theta ), color=1, size=0.02)+
  geom_hline(aes(yintercept=mxt), color=2,linetype="dashed", size=.02)+
  geom_hline(aes(yintercept=mnt), color=2,linetype="dashed", size=.02)+
  scale_y_continuous(name = expression(Deviation~from~daily~mean~of~theta~angle~','~degree))+
  theme_bw()
  #geom_smooth(aes(x=time,y=theta_d-theta ), color=3, size=0.02, se=T, span=.1,method = "loess")+
  #scale_y_continuous(limits=c(-10,10))+
  
graph


RUDN


RUDN = RUDNdata[[2]]
RUDN = RUDN %>%filter(doy>180)
RUDN %>% group_by(id)%>% summarise(Sp = as.factor(Species)%>% levels)
RUDN = two_sigma_weekly_flagging(RUDN,u)
RUDN = two_sigma_weekly_flagging(RUDN,gz2)
RUDN = two_sigma_weekly_flagging(RUDN,theta)
RUDN = radiation_flagging(RUDN)
RUDN$NDVI[!RUDN$rad_flag]=NA
RUDN = RUDN %>% group_by(doy,id) %>% mutate(psi_d = mean(psi, na.rm = T),
                                            phi_d = mean(phi, na.rm = T), 
                                            theta_d = mean(theta, na.rm = T),
) %>% ungroup()


HORT = HORTdata[[2]] %>% group_by(id) %>% mutate(mxt=max(theta_d-theta),
                                        mnt=min(theta_d-theta))


graph = ggplot(HORT%>%filter(!u_f))+
  geom_step( aes(x=time,y=VPD/25), color=alpha(4,0.5), size=.02, )+
  geom_line( aes(x=time,y=u), size=.02)+
  geom_smooth( aes(x=time,y=NDVI/8), color=3, size=.02, span=1)+
  #geom_point( aes(x=time,y=NDVI/8), color=3, size=.02)+
  scale_y_continuous(name = expression(Sap~flow~density~" "~l~h^{-1}~m^{-2}),
                     sec.axis = sec_axis(~.*25, name = "VPD, kPa", labels = function(b) { round(b * 1, 2)}),
                     limits = c(0,0.15))+
  facet_wrap( vars(Species,id),  nrow = 4, strip.position = "bottom",labeller = label_bquote(.(Species) - .(id)))
graph+theme_bw()


graph = ggplot(HORT%>%filter(!theta_f))+
  facet_wrap( vars(Species,id),  nrow = 2, strip.position = "bottom",labeller = label_bquote(.(Species) - .(id)))+
  geom_line(aes(x=time,y=theta_d-theta ), color=1, size=0.02)+
  geom_hline(aes(yintercept=mxt), color=2,linetype="dashed", size=.02)+
  geom_hline(aes(yintercept=mnt), color=2,linetype="dashed", size=.02)+
  scale_y_continuous(name = expression(Deviation~from~daily~mean~of~theta~angle~','~degree))+
  theme_bw()
#geom_smooth(aes(x=time,y=theta_d-theta ), color=3, size=0.02, se=T, span=.1,method = "loess")+
#scale_y_continuous(limits=c(-10,10))+

graph

plotbunch = AllData%>%group_by(load, Species, doy, id) %>% mutate(update = length(id))%>%
  summarise(sFlux = sum(Flux, na.rm=T), readings = mean(update), diam = mean(diam, na.rm=T), 
            time=mean(time,na.rm=T), load_score = mean(load_score,na.rm=T)) %>%
  mutate(suFlux = sFlux*readings/24) %>%
  group_by(load,Species, doy) %>% summarise(Flux = mean(suFlux, na.rm=T), d = mean(diam), 
                                            time=as.Date(mean(time,na.rm=T)), load_score = mean(load_score,na.rm=T)) %>% 
  group_by(Species)%>%
  do(Flux = ggplot(data = .)
     +geom_smooth(aes(x=time,y=Flux, group = load, color=load, fill = load))
     #+geom_ribbon(aes(x=time,y=Flux, group = load, color=load, se=FALSE))
     +geom_point(aes(x=time,y=Flux, group = load, color=load),size=.1)
     +scale_x_date(date_breaks = "1 month", date_labels = "%b", date_minor_breaks = "1 week",
                   limits = c(as.Date("01.05.2019", "%d.%m.%Y"), as.Date("01.10.2019", "%d.%m.%Y")), name = NULL)
     +scale_y_continuous( limits = c(0,75), name = expression(Скорость~" "~сокотечения~" "~л~д^-1))
     +scale_color_viridis_d(guide=FALSE)
     +scale_fill_viridis_d(name = "Уровень \nантропогенной\nнагрузки")
     +theme_bw()
     
  )
data$load_score%>%unique()
plotbunch[1,2][[1]]
plotbunch[2,2][[1]]
plotbunch[4,2][[1]]
plotbunch[8,2][[1]]
plotbunch[10,2][[1]]
plotbunch[11,2][[1]]
plotbunch[16,2][[1]]
plotbunch[20,2][[1]]





write.csv(file="acer_spectra.csv", tt_acer)
